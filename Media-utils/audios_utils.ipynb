{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gizeh\n",
    "!pip install moviepy --upgrade\n",
    "!pip install ffmpeg --upgrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get audio samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# French great podcast \n",
    "!wget https://audio.audiomeans.fr/file/eiYNOubrDD/65beb744-01fc-40e2-8bb0-312c16855cbb.mp3 \n",
    "!mv *.mp3 ../assets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English podcast\n",
    "!gsutil cp gs://github-repo/generative-ai/gemini/long-context/*.mp3 ../assets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the quality of the he audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub.utils import mediainfo\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def change_bitrate(file    ,root_dir = \"../assets/\", output_dir = \"../assets/resampling/\"):\n",
    "    media_info = mediainfo(root_dir+file)\n",
    "    print(media_info)\n",
    "    original_bitrate = media_info['bit_rate']\n",
    "\n",
    "    print(f\"original_bitrate = {original_bitrate}\") \n",
    "    bitrates = [#original_bitrate]# \n",
    "        \"64k\", \"128k\", \"256k\"\n",
    "        #, 312000\n",
    "        ]\n",
    "\n",
    "    frame_rates = [8000, 16000, 22000, 44000, 48000]\n",
    "\n",
    "    frame_rate = \"\"\n",
    "    # Iterate over each audio files\n",
    "    for bitrate in bitrates:\n",
    "        for frame_rate in frame_rates:\n",
    "            sound = AudioSegment.from_mp3(root_dir+file,\n",
    "                                        # 2 byte (16 bit) samples\n",
    "                                        #sample_width=1,\n",
    "                                        # frame rate\n",
    "                                        frame_rate=frame_rate,\n",
    "                                        # Mono\n",
    "                                        channels=1\n",
    "                                        )\n",
    "            \n",
    "\n",
    "            print(80*\"__\")\n",
    "            print(f\"file = {file}\")\n",
    "\n",
    "            print(f\"duration_seconds = {sound.duration_seconds}\")\n",
    "            print(f\"sample_width = {sound.sample_width}\")\n",
    "            print(f\"channels = {sound.channels}\")\n",
    "            print(f\"frame_rate = {sound.frame_rate}\")\n",
    "            sound = sound.set_frame_rate(frame_rate)\n",
    "            print(f\"frame_rate updated = {sound.frame_rate}\")\n",
    "\n",
    "            sound.export(output_dir+f\"{file}-{bitrate}-{frame_rate}.mp3\" , format=\"mp3\"\n",
    "                        , bitrate=bitrate\n",
    "                        )\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': '0', 'codec_name': 'mp3', 'codec_long_name': 'MP3 (MPEG audio layer 3)', 'profile': 'unknown', 'codec_type': 'audio', 'codec_tag_string': '[0][0][0][0]', 'codec_tag': '0x0000', 'sample_fmt': 'fltp', 'sample_rate': '44100', 'channels': '2', 'channel_layout': 'stereo', 'bits_per_sample': '0', 'initial_padding': '0', 'id': 'N/A', 'r_frame_rate': '0/0', 'avg_frame_rate': '0/0', 'time_base': '1/14112000', 'start_pts': '353600', 'start_time': '0.025057', 'duration_ts': '69358141440', 'duration': '4914.834286', 'bit_rate': '128150', 'max_bit_rate': 'N/A', 'bits_per_raw_sample': 'N/A', 'nb_frames': 'N/A', 'nb_read_frames': 'N/A', 'nb_read_packets': 'N/A', 'DISPOSITION': {'default': '0', 'dub': '0', 'original': '0', 'comment': '0', 'lyrics': '0', 'karaoke': '0', 'forced': '0', 'hearing_impaired': '0', 'visual_impaired': '0', 'clean_effects': '0', 'attached_pic': '0', 'timed_thumbnails': '0', 'non_diegetic': '0', 'captions': '0', 'descriptions': '0', 'metadata': '0', 'dependent': '0', 'still_image': '0'}, 'filename': '../assets/65beb744-01fc-40e2-8bb0-312c16855cbb.mp3', 'nb_streams': '1', 'nb_programs': '0', 'nb_stream_groups': '0', 'format_name': 'mp3', 'format_long_name': 'MP2/3 (MPEG audio layer 2/3)', 'size': '78730068', 'probe_score': '51', 'TAG': {'title': '376', 'artist': 'Guillaume Vendé', 'genre': 'Podcast', 'encoded_by': 'auphonic.com', 'encoder': 'Lavf59.16.100', 'TIT3': 'Tous les liens sur https://techcafe.fr', 'comment': \"Dans cet épisode de Tech Café, nous plongeons dans les dernières innovations et actualités du monde technologique en nous concentrant sur plusieurs sujets captivants. Nous commençons par une analyse de l'arrestation surprise de Pavel Durov, le créateur de Telegram, en France. Nous examinons les implications de cette affaire pour l'application de messagerie controversée, qui est à la fois un outil de liberté d'expression et un canal potentiel pour des activités illégales. Les accusations portées contre Durov soulèvent des questions sur la responsabilité des plateformes en ligne dans la modération de contenu.\", 'lyrics-eng': \"Dans cet épisode de Tech Café, nous plongeons dans les dernières innovations et actualités du monde technologique en nous concentrant sur plusieurs sujets captivants. Nous commençons par une analyse de l'arrestation surprise de Pavel Durov, le créateur de Telegram, en France. Nous examinons les implications de cette affaire pour l'application de messagerie controversée, qui est à la fois un outil de liberté d'expression et un canal potentiel pour des activités illégales. Les accusations portées contre Durov soulèvent des questions sur la responsabilité des plateformes en ligne dans la modération de contenu.\"}}\n",
      "original_bitrate = 128150\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "AudioSegment.from_mp3() got an unexpected keyword argument 'frame_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m65beb744-01fc-40e2-8bb0-312c16855cbb.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mchange_bitrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 21\u001b[0m, in \u001b[0;36mchange_bitrate\u001b[0;34m(file, root_dir, output_dir)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bitrate \u001b[38;5;129;01min\u001b[39;00m bitrates:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frame_rate \u001b[38;5;129;01min\u001b[39;00m frame_rates:\n\u001b[0;32m---> 21\u001b[0m         sound \u001b[38;5;241m=\u001b[39m \u001b[43mAudioSegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_mp3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;66;43;03m# 2 byte (16 bit) samples\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;66;43;03m#sample_width=1,\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;66;43;03m# frame rate\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mframe_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;66;43;03m# Mono\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m80\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: AudioSegment.from_mp3() got an unexpected keyword argument 'frame_rate'"
     ]
    }
   ],
   "source": [
    "file_name = \"65beb744-01fc-40e2-8bb0-312c16855cbb.mp3\"\n",
    "change_bitrate(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the format ==> Convert to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/julienmiquel/dev/STT/assets/Interview-Stephane-Gachet-JO.wav'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from audioedit import combine_audio_into_video\n",
    "from moviepy.editor import VideoFileClip, TextClip, ColorClip\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip\n",
    "from pydub.utils import mediainfo\n",
    "\n",
    "def convert_to_wav_16k(audio_path):\n",
    "    output_filename = audio_path.replace(\".mp3\", \".wav\") \n",
    "    AudioSegment.from_mp3(audio_path).export(output_filename, format=\"wav\", parameters=[\"-ar\", \"16000\"])\n",
    "\n",
    "    return output_filename\n",
    "\n",
    "def convert_to_video(audio_path):\n",
    "    output_filename = audio_path.replace(\".mp3\", \".mp4\") \n",
    "    #output_filename = audio_path + \".mp4\"\n",
    "    # original_bitrate = mediainfo(audio_path)['bit_rate']\n",
    "    # print(\"original_bitrate:\",original_bitrate)\n",
    "\n",
    "    # print(mediainfo(audio_path))\n",
    "    \n",
    "    # Load audio clips\n",
    "    audio_clips = AudioFileClip(audio_path)\n",
    "    total_audio = audio_clips.duration \n",
    "    print(f\"total_audio = {total_audio}\")\n",
    "    video_clip = ColorClip(size=(1,1), color=(255,255,255) #, duration=total_audio\n",
    "                           )\n",
    "\n",
    "    # Combine and save the video\n",
    "    video_clip = video_clip.set_audio(audio_clips).set_duration(total_audio)\n",
    "    \n",
    "    #video_clip.set_duration(total_audio)\n",
    "    video_clip.write_videofile(\n",
    "        filename=output_filename, fps=1, codec=\"libx264\",\n",
    "                        bitrate=\"1k\", \n",
    "                        audio=True, audio_fps=16000,\n",
    "                        preset=\"medium\",\n",
    "                        audio_nbytes=4, audio_codec=\"libmp3lame\",\n",
    "                        audio_bitrate=\"128k\", audio_bufsize=2000,\n",
    "                        #temp_audiofile=None,\n",
    "                        rewrite_audio=False, remove_temp=True,\n",
    "                        write_logfile=False, verbose=True,\n",
    "                        #threads=None, \n",
    "                        #ffmpeg_params=None\n",
    "    )\n",
    "\n",
    "    return output_filename\n",
    "        # output_filename, #codec=\"libx264\",\n",
    "        #                                                   audio = True, fps=1)\n",
    "\n",
    "file_name = \"/Users/julienmiquel/dev/STT/assets/Interview-Stephane-Gachet-JO.mp3\"\n",
    "\n",
    "\n",
    "#convert_to_video(file_name)    \n",
    "convert_to_wav_16k(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_file_path = /Users/julienmiquel/dev/STT/assets/Interview-Stephane-Gachet-JO.mp4 - gcs_bucket_name = ml-demo-eu - gcs_file_name = stt/Interview-Stephane-Gachet-JO.mp4\n",
      "upload_from_filename : local_file_path = /Users/julienmiquel/dev/STT/assets/Interview-Stephane-Gachet-JO.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Blob: ml-demo-eu, stt/Interview-Stephane-Gachet-JO.mp4, 1725701453253948>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcs.write_file_to_gcs(config.BUCKET,f\"stt/Interview-Stephane-Gachet-JO.mp4\",\"/Users/julienmiquel/dev/STT/assets/Interview-Stephane-Gachet-JO.mp4\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_audio = 985.42\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-32.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-32TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-32.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-32.mp4\n",
      "total_audio = 536.76\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-33.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-33TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-33.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-33.mp4\n",
      "total_audio = 1168.63\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-31.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-31TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-31.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-31.mp4\n",
      "total_audio = 1270.7\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-19.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-19TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-19.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-19.mp4\n",
      "total_audio = 556.94\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-18.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-18TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-18.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-18.mp4\n",
      "total_audio = 594.31\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-30.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-30TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-30.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-30.mp4\n",
      "total_audio = 611.16\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-20.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-20TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-20.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-20.mp4\n",
      "total_audio = 1442.74\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-34.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-34TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-34.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-34.mp4\n",
      "total_audio = 1245.62\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-35.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-35TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-35.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-35.mp4\n",
      "total_audio = 1013.38\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-21.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-21TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-21.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-21.mp4\n",
      "total_audio = 572.54\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-37.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-37TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-37.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-37.mp4\n",
      "total_audio = 518.47\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-36.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-36TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-36.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-36.mp4\n",
      "total_audio = 943.25\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-13.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-13TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-13.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-13.mp4\n",
      "total_audio = 756.41\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-12.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-12TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-12.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-12.mp4\n",
      "total_audio = 920.59\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-10.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-10TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-10.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-10.mp4\n",
      "total_audio = 590.69\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-38.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-38TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-38.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-38.mp4\n",
      "total_audio = 1032.36\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-4.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-4TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-4.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-4.mp4\n",
      "total_audio = 574.37\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-39.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-39TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-39.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-39.mp4\n",
      "total_audio = 971.62\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-11.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-11TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-11.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-11.mp4\n",
      "total_audio = 593.9\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-15.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-15TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-15.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-15.mp4\n",
      "total_audio = 1172.28\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-0.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-0TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-0.mp4\n",
      "total_audio = 1209.26\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-1.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-1TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-1.mp4\n",
      "total_audio = 532.34\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-14.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-14TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-14.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-14.mp4\n",
      "total_audio = 1127.81\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-16.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-16TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-16.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-16.mp4\n",
      "total_audio = 1033.2\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-3.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-3TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-3.mp4\n",
      "total_audio = 1063.01\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-2.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-2TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-2.mp4\n",
      "total_audio = 198.98\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-dataTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data.mp4\n",
      "total_audio = 681.36\n",
      "Moviepy - Building video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-17.mp4.\n",
      "MoviePy - Writing audio in stt-synthetic-data-17TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-17.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/julienmiquel/dev/STT/stt/stt-synthetic-data-17.mp4\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "root_dir = \"/Users/julienmiquel/dev/STT/stt/\"\n",
    "# Get a list of all TSV files in the current folder\n",
    "mp3_files = glob.glob(root_dir=root_dir, pathname=\n",
    "                    \"*.mp3\")                      \n",
    "\n",
    "wer_results = {}\n",
    "# Iterate over each prompt file\n",
    "for mp3_file in mp3_files:\n",
    "    convert_to_video(root_dir+mp3_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg in ./.venv/lib/python3.12/site-packages (1.4)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install sequence-evaluate rouge bleu transformers sentence-transformers torch rouge numpy seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from seq_eval import SeqEval\n",
    "\n",
    "evaluator = SeqEval()\n",
    "\n",
    "root_dir = \"/Users/julienmiquel/dev/STT/tests/\"\n",
    "# Get a list of all TSV files in the current folder\n",
    "tsv_files = glob.glob(root_dir=root_dir, pathname=\n",
    "                      \"4_short_*.tsv\")\n",
    "                      #\"2_long*0.tsv\")\n",
    "\n",
    "file_ref = \"4_short2_gemini-1.5-pro-001_0.tsv\"\n",
    "file_candidate = \"4_short_gemini-1.5-pro-001_0.tsv\"\n",
    "\n",
    "# Read the TSV file into a dataframe\n",
    "df_ref = pd.read_csv(root_dir+file_ref, sep='\\t')\n",
    "df_candidate = pd.read_csv(root_dir+file_candidate, sep='\\t')\n",
    "    \n",
    "column_analyze = \"text\" # \"speakerid\" #\n",
    "references = df_ref[column_analyze].to_list()\n",
    "candidates = df_candidate[column_analyze].to_list()\n",
    "embed_ref = embed_text(references)\n",
    "embed_candidate = embed_text(candidates)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = evaluator.evaluate(candidates, references, verbose=True)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cos_sim_array = cosine_similarity(X=embed_ref, Y=embed_candidate)\n",
    "\n",
    "# display as DataFrame\n",
    "axe = 'name'\n",
    "# apply lambda to each row of the references list to get the first 5 letters of each string in the list\n",
    "references_shorten = pd.DataFrame({'name': references})['name'].apply(lambda x: str(x)[0:100]).to_list()\n",
    "candidates_shorten = pd.DataFrame({'name': candidates})['name'].apply(lambda x: str(x)[0:100]).to_list()\n",
    "\n",
    "#df_sim = pd.DataFrame(cos_sim_array, index=references, columns=candidates)\n",
    "df_sim = pd.DataFrame(cos_sim_array, index=references, columns=candidates)\n",
    "\n",
    "print(f\"columns = {len(df_sim.columns)}\")\n",
    "print(f\"rows = {len(df_sim.index)}\")\n",
    "\n",
    "while len(df_sim.columns) < len(df_sim.values):\n",
    "    id = df_sim.max(axis=1).idxmin() #.loc( df_sim.idxmax( axis='columns')) #.idxmin(axis='columns') #.apply(lambda x: np.max(x), axis='rows')\n",
    "    print(f\"{id}  =  {df_sim[id].max()}\")\n",
    "    print(f\"drop id = {id}\")\n",
    "    df_sim = df_sim.columns.drop(id)\n",
    "    print(f\"columns = {len(df_sim.columns)}\")\n",
    "    print(f\"rows = {len(df_sim.index)}\")    \n",
    "    \n",
    "\n",
    "while len(df_sim.columns) > len(df_sim.values):\n",
    "    id = df_sim.max(axis=0).idxmin() #.loc( df_sim.idxmax( axis='columns')) #.idxmin(axis='columns') #.apply(lambda x: np.max(x), axis='rows')\n",
    "    print(f\"drop id = {id}\")\n",
    "    df_sim.drop(index=id)\n",
    "    print(f\"columns = {len(df_sim.columns)}\")\n",
    "    print(f\"rows = {len(df_sim.index)}\")    \n",
    "\n",
    "#df_sim#.idxmax( axis='columns')\n",
    "\n",
    "\n",
    "#df_sim\n",
    "# filter value inferior to 0.95\n",
    "#df_sim.loc[ (df_sim['max'] < 0.75)]\n",
    "\n",
    "#df_sim#['max'].idxmin( )\n",
    "#df_sim['max'].filter( ,axis = 'index').idxmin()\n",
    "# df_max = pd.DataFrame(df_sim.apply(lambda x: np.max(x), axis='rows'))\n",
    "# df_max.columns = [\"value\"]\n",
    "#df_max.apply(lambda x: np.min(x), axis='columns')\n",
    "\n",
    "#df_sim['max'].min() #[df_max[\"value\"] == df_max[\"max\"].min()] #.apply(lambda x: np.min(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(df_sim,\n",
    "                 #annot=True, \n",
    "                 cmap=\"crest\")\n",
    "#ax.xaxis.tick_top()\n",
    "ax.set_xticklabels(candidates_shorten, rotation=90)\n",
    "ax.set_yticklabels(references_shorten)\n",
    "ax.set_title(f'Cosine Similarity for {column_analyze} (text are truncated)'  )\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_array = np.array(embed_ref, dtype=np.float32)\n",
    "# tsne = TSNE(random_state=0, n_iter=250)\n",
    "# tsne_results = tsne.fit_transform(embeddings_array)\n",
    "\n",
    "# df_tsne = pd.DataFrame(tsne_results, columns=[\"TSNE1\", \"TSNE2\"])\n",
    "# df_tsne[\"target\"] = df[\"target\"]  # Add labels column from df_train to df_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from typing import List, Optional\n",
    "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
    "\n",
    "\n",
    "def embed_text(\n",
    "    texts: List[str] ,\n",
    "    task: str = \"RETRIEVAL_DOCUMENT\",\n",
    "    model_name: str = \"text-embedding-004\",\n",
    "    dimensionality: Optional[int] = 256,\n",
    ") -> List[List[float]]:\n",
    "    \"\"\"Embeds texts with a pre-trained, foundational model.\"\"\"\n",
    "    model = TextEmbeddingModel.from_pretrained(model_name)\n",
    "    inputs = [TextEmbeddingInput(text, task) for text in texts]\n",
    "    kwargs = dict(output_dimensionality=dimensionality) if dimensionality else {}\n",
    "    embeddings = model.get_embeddings(inputs, **kwargs)\n",
    "    return [embedding.values for embedding in embeddings]\n",
    "\n",
    "#embed_text([\"banana muffins? \", \"banana bread? banana muffins?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_file =  json.loads(open(\"./whisper/whisper_UGC - meeting.mp3_medium.json\").read())\n",
    "df_whisper = pd.DataFrame(whisper_file[\"segments\"])\n",
    "df_whisper.drop(columns=[\"id\",\"seek\",\"tokens\",\"temperature\",\"avg_logprob\",\"compression_ratio\",\"no_speech_prob\"], inplace = True)\n",
    "\n",
    "df_whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "root_dir = \"/Users/julienmiquel/dev/STT/tests/\"\n",
    "# Get a list of all TSV files in the current folder\n",
    "tsv_files = glob.glob(root_dir=root_dir, pathname=\n",
    "                      \"4_short_*.tsv\")\n",
    "                      #\"2_long*0.tsv\")\n",
    "\n",
    "if len(tsv_files) > 0:\n",
    "    print(\"Found TSV files\")\n",
    "    # Create an empty list to store the dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate over each TSV file\n",
    "    for file in tsv_files:\n",
    "        # Read the TSV file into a dataframe\n",
    "        df = pd.read_csv(root_dir+file, sep='\\t')\n",
    "        df['file'] = file\n",
    "        \n",
    "        # Append the dataframe to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate all dataframes into a single dataframe\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Now you have a single dataframe 'combined_df' containing data from all TSV files\n",
    "    print(combined_df)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________________________________________\n",
      "file = JO-stt.mp3-64.mp3\n",
      "duration_seconds = 3691.8595918367346\n",
      "sample_width = 2\n",
      "channels = 1\n",
      "frame_rate = 44100\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.utils import mediainfo_json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "root_dir = \"/Users/julienmiquel/dev/STT/assets/\"\n",
    "output_dir = \"/Users/julienmiquel/dev/STT/assets/resampling/\"\n",
    "# Get a list of all TSV files in the current folder\n",
    "mp3_files = glob.glob(root_dir=root_dir, pathname=\n",
    "                      \"*.mp3\")\n",
    "                      #\"2_long*0.tsv\")\n",
    "bitrates = [64, 92, 128, 256, 312]\n",
    "\n",
    "# Iterate over each TSV file\n",
    "for file in mp3_files:\n",
    "    prompt = \"\"\"Chapterize the audio content by grouping the audio content into chapters by detecting silence. \n",
    "Please only capture key events and highlights. If you are not sure about any info, please do not make it up. \n",
    "Return the result in the JSON format with keys as follows : 'timecode_start', 'timecode_stop'\"\"\"\n",
    "\n",
    "    sound = AudioSegment.from_mp3(root_dir+file)\n",
    "    print(80*\"__\")\n",
    "    print(f\"file = {file}\")\n",
    "\n",
    "    print(f\"duration_seconds = {sound.duration_seconds}\")\n",
    "    print(f\"sample_width = {sound.sample_width}\")\n",
    "    print(f\"channels = {sound.channels}\")\n",
    "    print(f\"frame_rate = {sound.frame_rate}\")\n",
    "    \n",
    "    sound.export(output_dir+file+f\"-{bitrate}.mp3\", format=\"mp3\", bitrate=bitrate)\n",
    "    break\n",
    "    \n",
    "\n",
    "#print(f\"duration = {sound.duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/Users/julienmiquel/dev/STT/assets/\"\n",
    "output_dir = \"/Users/julienmiquel/dev/STT/assets/assets_splitted/\"\n",
    "\n",
    "\n",
    "def splitAudio(root_dir, file, start, stop, output_dir):\n",
    "    sound = AudioSegment.from_mp3(root_dir+file)\n",
    "    print(80*\"__\")\n",
    "    print(f\"file = {file}\")\n",
    "\n",
    "    sound = sound[start:stop]\n",
    "    print(f\"duration_seconds = {sound.duration_seconds}\")\n",
    "    print(f\"sample_width = {sound.sample_width}\")\n",
    "    print(f\"channels = {sound.channels}\")\n",
    "    print(f\"frame_rate = {sound.frame_rate}\")\n",
    "    file_segment = output_dir+file+f\"-{start}-{stop}.mp3\"\n",
    "\n",
    "    sound.export(file_segment, format=\"mp3\")\n",
    "    return file_segment\n",
    "\n",
    "splitAudio(root_dir, \"Lionel 1.mp3\", 10, 15,output_dir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"id\": \\n\"speaker_0\", \"text\": \"de de d\\'interview pour euh pour de la retranscription automatique\", \"time_start\": 0, \"time_stop\": 11000}, {\"id\": \"speaker_1\", \"text\": \"Ah oui d\\'accord\", \"time_start\": 11000, \"time_stop\": 13000}, {\"id\": \"speaker_0\", \"text\": \"Et alors du coup pendant quelques pendant 2 3 minutes je vais enregistrer notre conversation sur mon téléphone pour voir si ça marche parce que je dois la renvoyer euh coucou Lionel je vais tu vois tu vas recevoir ton ton texte là Enfin non ton ton son Euh et après je je vous demanderais s\\'il vous plaît de de de couper votre enfin de de mettre votre téléphone en mode avion parce que Ah super Parce que sinon ça provoque en fait Ah oui en mode silencieux mais Oui mais même en mode avion Voilà mais même en mode avion parce que sinon ça provoque des interférences avec cette petite machine là qui est devant nous\", \"time_start\": 13200, \"time_stop\": 81000}, {\"id\": \"speaker_1\", \"text\": \"D\\'accord d\\'accord si ça marche Oui il est toujours Oui\", \"time_start\": 31000, \"time_stop\": 54000}, {\"id\": \"speaker_2\", \"text\": \"Oui\", \"time_start\": 63000, \"time_stop\": 65000}, {\"id\": \"speaker_1\", \"text\": \"Oui\", \"time_start\": 67000, \"time_stop\": 68000}, {\"id\": \"speaker_2\", \"text\": \"Ça provoque\", \"time_start\": 71000, \"time_stop\": 74000}, {\"id\": \"speaker_1\", \"text\": \"Ça marche\", \"time_start\": 81000, \"time_stop\": 84000}, {\"id\": \"speaker_0\", \"text\": \"Alors voilà Hop Euh César il a déjà mis son téléphone en mode avion parce qu\\'il est habitué Il est ici dans son jardin\", \"time_start\": 84000, \"time_stop\": 112000}, {\"id\": \"speaker_2\", \"text\": \"Oui oui Il est ici dans son jardin C\\'est fait\", \"time_start\": 112000, \"time_stop\": 128000}, {\"id\": \"speaker_0\", \"text\": \"Euh merci\", \"time_start\": 129000, \"time_stop\": 136000}, {\"id\": \"speaker_1\", \"text\": \"Merci J\\'ai j\\'ai entendu ce matin euh que Daniel Fievet faisait une annonce sur euh sur euh une émission sur le le vin du futur Je me suis demandé si c\\'était vous qui étiez invitée\", \"time_start\": 140000, \"time_stop\": 167000}, {\"id\": \"speaker_2\", \"text\": \"C\\'était pas Carrey C\\'est ça Oui c\\'est ça Oui oui c\\'est après-midi\", \"time_start\": 167000, \"time_stop\": 178000}, {\"id\": \"speaker_0\", \"text\": \"Ah voilà Vous y allez\", \"time_start\": 178000, \"time_stop\": 184000}, {\"id\": \"speaker_2\", \"text\": \"Oui Ah vous dites décidément Ben en fait c\\'est un peu pour ça que j\\'ai proposé ce jour parce que comme ça je suis dans le dans le secteur et puis\", \"time_start\": 184000, \"time_stop\": 213000}, {\"id\": \"speaker_0\", \"text\": \"Ah oui parce que vous allez enregistrer à côté\", \"time_start\": 213000, \"time_stop\": 221000}, {\"id\": \"speaker_2\", \"text\": \"Oui oui oui oui oui C\\'est mon collègue qui qui sera en studio à Paris Jean-Marc Touzard ben justement le coauteur du livre voilà Et et Montpellier Oui il est Montpellier lui c\\'est ça Oui il est à Montpellier voilà Et et moi je je C\\'est la journée médiatique de madame Roland aujourd\\'hui Exactement Voilà On on rationalise un peu tout Et porte-parole et vous venez au micro Voilà exactement\", \"time_start\": 221000, \"time_stop\": 298000}, {\"id\": \"speaker_1\", \"text\": \"D\\'accord Absolument ouais Le Montpellier Oui il est Montpellier lui c\\'est ça\", \"time_start\": 238000, \"time_stop\": 263000}, {\"id\": \"speaker_0\", \"text\": \"OK Lionel donc tu as désormais un échantillon de de 2 minutes euh en sachant que ce téléphone était plus proche de moi que de madame Roland et tu vas entendre une troisième voix celle de César vers la fin Euh donc voilà euh dis-moi si tu as besoin de plus de son ou pas Merci d\\'avance\", \"time_start\": 310000, \"time_stop\": 499000}] '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gemini = GenerativeModel(model_name)\n",
    "\n",
    "# Iterate over each mp3 file\n",
    "file = \"UGC_meeting.mp3\"\n",
    "file = \"Lionel 1.mp3\"\n",
    "\n",
    "audio1 = Part.from_uri(\n",
    "    mime_type=\"audio/mp3\",\n",
    "    uri=f\"gs://ml-demo-eu/datasets/input/{file}\")\n",
    "\n",
    "# prompt_split = \"\"\"Chapterize the audio content by grouping the audio content into chapters by detecting silence. \n",
    "# Please only capture key events and highlights. If you are not sure about any info, please do not make it up. \n",
    "# Return the result in the JSON format with keys as follows : 'timecode_start', 'timecode_stop' 'description'\n",
    "# \"\"\"\n",
    "\n",
    "prompt = \"\"\"<Task>\n",
    "    Transcribe in {language} this recording from the time_start 0 to the time_stop 500 of the recording.\n",
    "    Identify each persons with their name and their genre if possible.\n",
    "    Accuracy: Prioritize precision in capturing spoken words. Strive to minimize errors and misinterpretations.\n",
    "    Clarity: Ensure the transcribed text flows naturally and is easy to understand. Punctuate sentences appropriately.\n",
    "\n",
    "    STOP generating output properly (keep a valid JSON) after generating 8000 characters in output.\n",
    "</Task>\n",
    "\n",
    "<answer_format>\n",
    "    JSON keys: id (speaker id), start (time_start), stop (time_stop), text.\n",
    "    Id is numeric id of the speaker (speaker_id). Check twice the speaker id is correctly associated with the text.\n",
    "    start (time_start) and stop (time_stop) are the full time in miliseconds and not truncated.\n",
    "    text is the transcription of the voice of the speaker.\n",
    "</answer_format>\n",
    "\"\"\"\n",
    "\n",
    "response_schema = {\n",
    "    \"type\": \"ARRAY\",\n",
    "    \"items\": {\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"time_start\": {\n",
    "                \"type\": \"INTEGER\"\n",
    "            },\n",
    "            \"time_stop\": {\n",
    "                \"type\": \"INTEGER\"\n",
    "            },\n",
    "            \"id\": {\n",
    "                \"type\": \"STRING\"\n",
    "            },\n",
    "            \"text\": {\n",
    "                \"type\": \"STRING\"\n",
    "            }\n",
    "        },\n",
    "        # \"required\": [\n",
    "        #     \"timecode_start\"\n",
    "        # ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# generation_config_json = {\n",
    "#       \"max_output_tokens\": 8192,\n",
    "#       \"temperature\": 0.0,\n",
    "#       \"top_p\": 1,\n",
    "#       \"response_mime_type\": \"application/json\",\n",
    "#       \"response_schema\" : response_schema\n",
    "#       #\"enableStandaloneAudioTimestampsToModels\": True,\n",
    "      \n",
    "#   }\n",
    "\n",
    "generation_config_json = generation_config=GenerationConfig(\n",
    "    max_output_tokens= 8192,\n",
    "    temperature= 0.0,\n",
    "    top_p= 0.0,\n",
    "    frequency_penalty = 0.5,\n",
    "    response_mime_type=\"application/json\", \n",
    "    response_schema=response_schema\n",
    "    )\n",
    "\n",
    "prompts = [audio1, prompt]\n",
    "response = model_gemini.generate_content(\n",
    "    contents=prompts,\n",
    "    generation_config=generation_config_json,\n",
    "    #safety_settings=safety_settings,\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "audio_split = json.load(response.text)\n",
    "audio_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_sequence(file):\n",
    "    from pydub import AudioSegment, silence\n",
    "\n",
    "    myaudio = AudioSegment.from_mp3(file)\n",
    "    dBFS=myaudio.dBFS\n",
    "\n",
    "    speak = silence.detect_nonsilent(myaudio, min_silence_len=500, silence_thresh=dBFS-20, seek_step=10)\n",
    "    speak_sequences = speak\n",
    "\n",
    "    #speak_sequences = [((start/1000),(stop/1000)) for start,stop in speak] #convert to sec\n",
    "\n",
    "    print(speak_sequences)\n",
    "    return speak_sequences\n",
    "\n",
    "speak_sequences = get_audio_sequence(root_dir+file)\n",
    "\n",
    "# filter speak_sequences when stop - start are less than 2 secondes\n",
    "speak_sequences_filtered = [(start, stop) for start, stop in speak_sequences if stop - start >= 1500]\n",
    "\n",
    "model_gemini = GenerativeModel(model_name)\n",
    "\n",
    "prompt = \"\"\"<Task>\n",
    "    Transcribe in {language} this recording from the time_start 0 to the time_stop 500 of the recording.\n",
    "    Identify each persons with their name and their genre if possible.\n",
    "    Accuracy: Prioritize precision in capturing spoken words. Strive to minimize errors and misinterpretations.\n",
    "    Clarity: Ensure the transcribed text flows naturally and is easy to understand. Punctuate sentences appropriately.\n",
    "\n",
    "    STOP generating output properly (keep a valid JSON) after generating 8000 characters in output.\n",
    "</Task>\n",
    "\n",
    "<answer_format>\n",
    "    JSON keys: id (speaker id), start (time_start), stop (time_stop), text.\n",
    "    Id is numeric id of the speaker (speaker_id). Check twice the speaker id is correctly associated with the text.\n",
    "    start (time_start) and stop (time_stop) are the full time in seconds and not truncated.\n",
    "    text is the transcription of the voice of the speaker.\n",
    "</answer_format>\n",
    "\"\"\"\n",
    "splited_files = []\n",
    "splited_answers = []\n",
    "for (start, stop) in speak_sequences_filtered:\n",
    "    \n",
    "    splited_file = splitAudio(root_dir,file, start, stop, output_dir)\n",
    "\n",
    "    # Load file bytes\n",
    "    with open(splited_file, \"rb\") as f:\n",
    "        file_part = Part.from_data(data=f.read(), mime_type=\"audio/mp3\")\n",
    "\n",
    "    print(splited_file)\n",
    "    splited_files.append(splited_file)\n",
    "\n",
    "    # Load contents\n",
    "    contents = [file_part, prompt]\n",
    "\n",
    "    # Send to Gemini with GenerationConfig\n",
    "    response = model_gemini.generate_content(contents, generation_config=generation_config_json)\n",
    "    print(response.text)\n",
    "    splited_answers.append(response.text)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Speech-to-Text client library\n",
    "from google.cloud import speech\n",
    "\n",
    "# Instantiates a client\n",
    "client = speech.SpeechClient() \n",
    "\n",
    "audio_content = None\n",
    "\n",
    "# transcribe speech\n",
    "audio = speech.RecognitionAudio(content=audio_content)\n",
    "\n",
    "diarizationConfig = speech.SpeakerDiarizationConfig(enable_speaker_diarization=True)\n",
    "\n",
    "config = speech.RecognitionConfig(\n",
    "    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz=24000,\n",
    "    language_code=\"fr-FR\",\n",
    "    model=\"default\",\n",
    "    audio_channel_count=1,\n",
    "    enable_word_confidence=True,\n",
    "    enable_word_time_offsets=True,\n",
    "    diarization_config = diarizationConfig,\n",
    ")\n",
    "\n",
    "# Detects speech in the audio file\n",
    "operation = client.long_running_recognize(config=config, audio=audio)\n",
    "\n",
    "print(\"Waiting for operation to complete...\")\n",
    "response = operation.result(timeout=90)\n",
    "\n",
    "for result in response.results:\n",
    "  print(\"Transcript: {}\".format(result.alternatives[0].transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_streaming(stream_file: str) -> speech.RecognitionConfig:\n",
    "    \"\"\"Streams transcription of the given audio file.\"\"\"\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with open(stream_file, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    # In practice, stream should be a generator yielding chunks of audio data.\n",
    "    stream = [content]\n",
    "\n",
    "    requests = (\n",
    "        speech.StreamingRecognizeRequest(audio_content=chunk) for chunk in stream\n",
    "    )\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"en-US\",\n",
    "    )\n",
    "\n",
    "    streaming_config = speech.StreamingRecognitionConfig(config=config)\n",
    "\n",
    "    # streaming_recognize returns a generator.\n",
    "    responses = client.streaming_recognize(\n",
    "        config=streaming_config,\n",
    "        requests=requests,\n",
    "    )\n",
    "\n",
    "    for response in responses:\n",
    "        # Once the transcription has settled, the first result will contain the\n",
    "        # is_final result. The other results will be for subsequent portions of\n",
    "        # the audio.\n",
    "        for result in response.results:\n",
    "            print(f\"Finished: {result.is_final}\")\n",
    "            print(f\"Stability: {result.stability}\")\n",
    "            alternatives = result.alternatives\n",
    "            # The alternatives are ordered from most likely to least.\n",
    "            for alternative in alternatives:\n",
    "                print(f\"Confidence: {alternative.confidence}\")\n",
    "                print(f\"Transcript: {alternative.transcript}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deepgram-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepgram import DeepgramClient, PrerecordedOptions\n",
    "\n",
    "# The API key we created in step 3\n",
    "DEEPGRAM_API_KEY = 'ac4855260ef2e43fb49307f2e58e69aee84e8f96'\n",
    "\n",
    "# Replace with your file path\n",
    "PATH_TO_FILE = root_dir + \"Lionel 1.mp3\"\n",
    "\n",
    "def main():\n",
    "    deepgram = DeepgramClient(DEEPGRAM_API_KEY)\n",
    "\n",
    "    with open(PATH_TO_FILE, 'rb') as buffer_data:\n",
    "        payload = { 'buffer': buffer_data }\n",
    "\n",
    "        options = PrerecordedOptions(\n",
    "            punctuate=True, model=\"nova-2\", language=\"fr\"\n",
    "        )\n",
    "\n",
    "        response = deepgram.listen.prerecorded.v('1').transcribe_file(payload, options)\n",
    "        print(response.to_json(indent=4))\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
