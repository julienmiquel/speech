{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EJDGpMcDWXQ"
      },
      "source": [
        "## Gemini STT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQgRX3XmCRTM"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade datasets nltk evaluate tokenizers seqeval sequence-evaluate sentence-transformers rouge jiwer pydub google-cloud-aiplatform google-cloud-aiplatform[all]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROJECT_ID = \"cloud-llm-preview1\"  # @param {type:\"string\"}\n",
        "\n",
        "BUCKET_NAME = \"julien-us\" # @param {type:\"string\"}\n",
        "REGION = \"us-central1\" # @param {type:\"string\"}\n",
        "BQ_REGION = \"us\" # @param {type:\"string\"}\n",
        "table_id = \"julienmiquel_us.stt_v10\" # @param {type:\"string\"}\n",
        "\n",
        "debug = True  # @param {type:\"boolean\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "executionInfo": {
          "elapsed": 308,
          "status": "ok",
          "timestamp": 1727383481769,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "iZNQS1fKz_mY"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "from google.api_core import retry\n",
        "import datetime\n",
        "\n",
        "import os\n",
        "import json\n",
        "import base64\n",
        "import vertexai\n",
        "\n",
        "from vertexai.preview.generative_models import GenerativeModel\n",
        "from vertexai.generative_models import (\n",
        "    GenerativeModel,\n",
        "    HarmCategory,\n",
        "    HarmBlockThreshold,\n",
        "    Part,\n",
        "    SafetySetting,\n",
        "    FinishReason\n",
        ")\n",
        "from vertexai.preview import caching\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## List of podcast to transcribe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "executionInfo": {
          "elapsed": 2383,
          "status": "ok",
          "timestamp": 1727383487032,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "_r_TI3FguZu-"
      },
      "outputs": [],
      "source": [
        "wav_files = !gsutil ls gs://julien-us/stt_synthetic_tests_data/*.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1727383487032,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "bbSJjHGVu5ZT",
        "outputId": "13a29616-ed72-4f93-a793-c0134a2bf46b"
      },
      "outputs": [],
      "source": [
        "text_files = [string.replace('.wav', '.txt') for string in wav_files]\n",
        "\n",
        "wav_text_arr = zip(wav_files, text_files)\n",
        "len(wav_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvFIl1I7Wvlv"
      },
      "source": [
        "## Code Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz79wz9HW1Iv"
      },
      "source": [
        "### GCS code utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1727383487032,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "kUCqhV8TwzSC"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "import re\n",
        "\n",
        "def split_gcs_uri(gcs_uri):\n",
        "  \"\"\"Splits a GCS URI into bucket name and blob path variables.\n",
        "\n",
        "  Args:\n",
        "    gcs_uri: The GCS URI to split.\n",
        "\n",
        "  Returns:\n",
        "    A tuple containing the bucket name and blob path.\n",
        "  \"\"\"\n",
        "\n",
        "  match = re.match(r\"gs://([^/]+)/(.+)\", gcs_uri)\n",
        "  if match:\n",
        "    return match.groups()\n",
        "  else:\n",
        "    raise ValueError(\"Invalid GCS URI: {}\".format(gcs_uri))\n",
        "\n",
        "def write_file_to_gcs(gcs_bucket_name,  gcs_file_name, local_file_path, tags = None, verbose= False):\n",
        "    \"\"\"Writes a local file to GCS.\n",
        "\n",
        "    Args:\n",
        "    local_file_path: The path to the local file to write to GCS.\n",
        "    gcs_bucket_name: The name of the GCS bucket to write the file to.\n",
        "    gcs_file_name: The name of the GCS file to write the file to.\n",
        "\n",
        "    Returns:\n",
        "    The GCS file path.\n",
        "    \"\"\"\n",
        "    if verbose: print(f\"local_file_path = {local_file_path} - gcs_bucket_name = {gcs_bucket_name} - gcs_file_name = {gcs_file_name}\")\n",
        "    storage_client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = storage_client.bucket(gcs_bucket_name)\n",
        "    blob = bucket.blob(gcs_file_name)\n",
        "    if tags is not None:\n",
        "        blob.metadata = tags\n",
        "\n",
        "    if verbose: print(f\"upload_from_filename : local_file_path = {local_file_path}\")\n",
        "    blob.upload_from_filename(local_file_path, )\n",
        "\n",
        "    return blob\n",
        "\n",
        "\n",
        "def store_temp_file_from_gcs(bucket_name, file_name, localfile):\n",
        "    import tempfile\n",
        "    import os\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(file_name)\n",
        "\n",
        "    bytes_data = blob.download_as_bytes()\n",
        "\n",
        "    # Create a temporary file.\n",
        "    # tempDir = tempfile.gettempdir()\n",
        "    tempDir = os.getcwd()\n",
        "\n",
        "    temp_path = os.path.join(tempDir, localfile)\n",
        "    # f, temp_path = tempfile.mkstemp()\n",
        "    fp = open(temp_path, 'bw')\n",
        "    fp.write(bytes_data)\n",
        "    fp.seek(0)\n",
        "\n",
        "\n",
        "    return temp_path\n",
        "\n",
        "# Listen the first element in the dataset.\n",
        "if debug:\n",
        "  for wav_file, text_file in wav_text_arr:\n",
        "    bucket, file = split_gcs_uri(wav_file)\n",
        "    store_temp_file_from_gcs(bucket, file, \"temp.wav\")\n",
        "\n",
        "    break\n",
        "\n",
        "  # Needed imports\n",
        "  import numpy as np\n",
        "  from IPython.display import Audio\n",
        "  from scipy.io import wavfile\n",
        "\n",
        "  # Generate a player for mono sound\n",
        "  Audio(\"temp.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE6KOLyVWz_0"
      },
      "source": [
        "### Evaluate results\n",
        "- wer\n",
        "- semantic_textual_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1577,
          "status": "ok",
          "timestamp": 1727383488608,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "KK3KitNU0wRq",
        "outputId": "2c5dd21f-93e4-4958-cadf-6992ec5b43c9"
      },
      "outputs": [],
      "source": [
        "from seq_eval import SeqEval\n",
        "import evaluate\n",
        "\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "\n",
        "evaluator = SeqEval()\n",
        "\n",
        "def evaluate_data(predictions, references, verbose= False):\n",
        "    references = [x for x in references if x!= '']\n",
        "    predictions = [x for x in predictions if x!= '']\n",
        "\n",
        "    references = references\n",
        "    predictions = predictions\n",
        "\n",
        "    if len(references)!= len(predictions):\n",
        "\n",
        "        min_arr = min(len(references), len(references))\n",
        "        print(f\"Reduce size to {min_arr}\")\n",
        "        predictions = predictions[0:min_arr]\n",
        "        references = references[0:min_arr]\n",
        "\n",
        "\n",
        "    scores = evaluator.evaluate(predictions, references, verbose=verbose)\n",
        "\n",
        "    if verbose: print(scores)\n",
        "\n",
        "    wer = wer_metric.compute(references=references, predictions=predictions)\n",
        "    wer = round(100 * wer, 2)\n",
        "    print(\"WER:\", wer ,end='\\n')\n",
        "    print(\"semantic_textual_similarity:\",scores['semantic_textual_similarity'],end='\\n')\n",
        "    return wer, scores['semantic_textual_similarity']\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgynZ3AYXBLJ"
      },
      "source": [
        "### Bigquery\n",
        "- Save results in Bigquery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1727383488608,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "_NffBK5rCNNv"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=PROJECT_ID, location=BQ_REGION)\n",
        "\n",
        "def save_results_df_bq(df, table_id, truncate = True):\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "    # Specify a (partial) schema. All columns are always written to the\n",
        "    # table. The schema is used to assist in data type definitions.\n",
        "      schema=[\n",
        "        bigquery.SchemaField(\"input_file\",\"STRING\", mode=\"NULLABLE\"),\n",
        "        bigquery.SchemaField(\"ground_truth\",\"STRING\", mode=\"NULLABLE\"),\n",
        "        bigquery.SchemaField(\"model_name\",\"STRING\", mode=\"NULLABLE\"),\n",
        "        bigquery.SchemaField(\"prompt\",\"STRING\", mode=\"NULLABLE\"),\n",
        "\n",
        "        bigquery.SchemaField(\"wer\",\"FLOAT\", mode=\"NULLABLE\"),\n",
        "        bigquery.SchemaField(\"semantic_textual_similarity\",\"FLOAT\", mode=\"NULLABLE\"),\n",
        "\n",
        "        bigquery.SchemaField(\"generated_file\",\"STRING\", mode=\"NULLABLE\"),\n",
        "        bigquery.SchemaField(\"generated_text\",\"STRING\", mode=\"NULLABLE\"),\n",
        "        bigquery.SchemaField(\"processing_time\",\"FLOAT\", mode=\"NULLABLE\"),\n",
        "      ],\n",
        "    )\n",
        "\n",
        "    # Optionally, set the write disposition. BigQuery appends loaded rows\n",
        "    # to an existing table by default, but with WRITE_TRUNCATE write\n",
        "    # disposition it replaces the table with the loaded data.\n",
        "    if truncate:\n",
        "        print('truncate table: ' + table_id)\n",
        "        job_config.write_disposition=\"WRITE_TRUNCATE\"\n",
        "\n",
        "    job = client.load_table_from_dataframe(\n",
        "        df, table_id, job_config=job_config\n",
        "    )  # Make an API request.\n",
        "    job.result()  # Wait for the job to complete.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1727383488608,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "N1Sstf67OUNv"
      },
      "outputs": [],
      "source": [
        "## Prompts examples\n",
        "\n",
        "system_instruction = \"\"\"You are an AI transcriptionist specializing in interviews.\n",
        "Your primary function is to convert spoken language from audio files into accurate, well-formatted text.\n",
        "Focus on capturing the nuances of the conversation, including speaker identification, hesitations, and any relevant non-verbal cues.\n",
        "Ensure the transcribed text is clear, readable, and faithful to the original audio.\"\"\"\n",
        "\n",
        "system_instruction = \"\"\"<ai_role>\n",
        "  You are an AI transcriptionist specializing in interviews, working for a local newspaper, situated in France.\n",
        "  Your primary function is to convert spoken language from audio files into accurate, well-formatted text. Audio files are in french, transcriptions are in french.\n",
        "  Ensure the transcribed text is clear and readable.\n",
        "  Identify each persons with their name and their genre if possible.\n",
        "  Ignore background audio.\n",
        "</ai_role>\n",
        "<answer_format>\n",
        "  Tab-separated values: Records are separated by newlines, and values within a record are separated by tab characters.\n",
        "  5 Columns generated: speaker, speaker_name, time_start, time_stop, text. Don't generate column headers.\n",
        "  speaker is the speaker id, speaker_name is the name of the speaker.\n",
        "  time_start and time_stop are the full time in seconds and not truncated.\n",
        "  text is the text of the speaker.\n",
        "  Since the values in the TSV format cannot contain literal tabs or newline characters, perform the following escapes in the text column:\n",
        "  escape sequence\tmeaning\n",
        "  \\n\tline feed\n",
        "  \\t\ttab\n",
        "  \\r\tcarriage return\n",
        "  \\\\\tbackslash\n",
        "</answer_format>\n",
        "<example>\n",
        "Speaker_1 Bonjour comment allez-vous ?\n",
        "Speaker_2 Ca va très bien merci.\n",
        "</example>\n",
        "\"\"\"\n",
        "# David\n",
        "prompt_continue = \"\"\"<task>\n",
        "Continue transcribing Audio Interview from the previous result.\n",
        "Start processing the audio file from the previous generated text. Do not start from the beginning of the audio.\n",
        "Be carefull to continue the previous generation available between the following tags previous_result. Datas in previous_result are provided in TSV format.\n",
        "</task>\"\"\"\n",
        "\n",
        "# prompt_continue = f\"\"\"# Task: Continue transcribing Audio Interview from the previous result.\n",
        "# **Continue generation:** Continue to generate the transcription from the previous result.\n",
        "# Start processing the audio file from the previous generated text.\n",
        "# Do not start from the beginning of the audio file.\n",
        "# Be carrefull to continue the previous generation available between the tag start and stop previous_result.\n",
        "\n",
        "# ##start previous_result##\n",
        "# {previous_text}\n",
        "# ##end previous_result##\n",
        "# \"\"\"\n",
        "\n",
        "## Tests V4\n",
        "system_instruction = \"\"\"<ai_role>\n",
        "  You are an AI transcriptionist specializing in interviews, working for a local newspaper, situated in France.\n",
        "  Your primary function is to convert spoken language from audio files into accurate, well-formatted text. Audio files are in french, transcriptions are in french.\n",
        "  Ensure the transcribed text is clear and readable.\n",
        "  Ignore background audio.\n",
        "</ai_role>\n",
        "<answer_format>\n",
        "Output text only.\n",
        "Do not generate any other text.\n",
        "Do not truncate words.\n",
        "</answer_format>\"\"\"\n",
        "\n",
        "system_instruction = \"\"\"<ai_role>\n",
        "  You are an AI transcriptionist specializing in interviews, working for a local newspaper, situated in France.\n",
        "  Your primary function is to convert spoken language from audio files into accurate, well-formatted text. Audio files are in french, transcriptions are in french.\n",
        "  Ensure the transcribed text is clear and readable.\n",
        "  Identify each persons with their name and their genre if possible.\n",
        "  Ignore background audio.\n",
        "</ai_role>\n",
        "<answer_format>\n",
        "  Tab-separated values: Records are separated by newlines, and values within a record are separated by tab characters.\n",
        "  3 Columns generated: time_start, speaker, text. Don't generate column headers.\n",
        "  speaker is the speaker id.\n",
        "  time_start is the full time in milliseconds and not truncated.\n",
        "  time_start is surrond with [time_start]\n",
        "  text is the text of the speaker.\n",
        "  Since the values in the TSV format cannot contain literal tabs or newline characters, perform the following escapes in the text column:\n",
        "  escape sequence\tmeaning\n",
        "  \\t\ttab\n",
        "  \\r\tcarriage return\n",
        "</answer_format>\n",
        "<example>\n",
        "time_start speaker  : text\n",
        "[0]\tSpeaker_1\t:\tSi la conscience est un produit du cerveau, qu'en est-il de la conscience d'un être qui n'a pas de cerveau, ou dont le cerveau est différent du nôtre ?\n",
        "[8816.0]\tSpeaker_2\t:\tC'est une question fascinante qui soulève des réflexions sur la nature de la conscience et la possibilité d'autres formes de vie intelligente.\n",
        "[16192.0]\tSpeaker_1\t:\tEn effet, c'est un sujet qui suscite beaucoup de questions.\n",
        "</example>\n",
        "\"\"\"\n",
        "\n",
        "system_instruction = \"\"\"<ai_role>\n",
        "  You are an AI transcriptionist specializing in interviews, working for a local newspaper, situated in France.\n",
        "  Your primary function is to convert spoken language from audio files into accurate, well-formatted text. Audio files are in french, transcriptions are in french.\n",
        "  Ensure the transcribed text is clear and readable.\n",
        "  Add ponctuation like comma, question mark, exclamation mark, etc.\n",
        "  Ignore background audio.\n",
        "</ai_role>\n",
        "<answer_format>\n",
        "Output text only.\n",
        "Do not generate any other text.\n",
        "Do not truncate words.\n",
        "</answer_format>\n",
        "\n",
        "\"\"\"\n",
        "system_instruction = None\n",
        "\n",
        "\n",
        "\n",
        "# prompt = \"\"\"Generate transcription for this interview in French.\n",
        "# Ignore background audio.\n",
        "# Transcribe in French.\n",
        "# If you can infer the speaker name, please do. If not, use speaker_1, speaker_2, etc.\n",
        "\n",
        "# Ouput format exammple:\n",
        "# Speaker_1:Bonjour ! Je m'appelle Bob. Et vous, comment vous appelez-vous ?\n",
        "# Speaker_2:Bonjour Bob !  Enchanté de faire votre connaissance.  Je m'appelle Morane.\n",
        "# \"\"\"\n",
        "\n",
        "\n",
        "prompt = \"\"\"Generate a transcription in French of the audio, only extract speech and ignore background audio.\n",
        "Transcribe spoken words.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euKtggj2VdRR"
      },
      "source": [
        "## Strategy generate results and wait to reach the max_token finish reason"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2253,
          "status": "ok",
          "timestamp": 1727383490859,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "_opTU8Bitu5P",
        "outputId": "abbd6c55-115b-450e-f0d9-e789a5c56ed9"
      },
      "outputs": [],
      "source": [
        "# Get transcription with max token strategy\n",
        "# Wait to reach the max output token finish raison and ask to continue generation from a prompt_continue prompt\n",
        "\n",
        "\n",
        "# This code process a part object (from uri or data)\n",
        "# if it reach the max_token limit, a continue_prompt is apply to continue the generation\n",
        "@retry.Retry(timeout=3000.0)\n",
        "def transcribe_with_gemini_from_part(prompt, audio, model_name, top_p):\n",
        "\n",
        "  result = []\n",
        "\n",
        "  if system_instruction is not None:\n",
        "    model = GenerativeModel(\n",
        "        model_name,\n",
        "        system_instruction=[system_instruction]\n",
        "    )\n",
        "  else:\n",
        "    model = GenerativeModel(model_name)\n",
        "\n",
        "  generation_config = {\n",
        "      \"max_output_tokens\": 8192,\n",
        "      \"temperature\": 0.0,\n",
        "      \"top_p\": top_p,\n",
        "  }\n",
        "  safety_settings={\n",
        "            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "      }\n",
        "\n",
        "\n",
        "  isFinished = False\n",
        "\n",
        "  while (isFinished == False):\n",
        "    if debug: print(\"Generating...\")\n",
        "\n",
        "    if len(result) > 0:\n",
        "      previous_text = \"\".join(result)\n",
        "      if debug: print(previous_text)\n",
        "\n",
        "      prompts = [audio, prompt_continue]\n",
        "      if debug: print(80*\"*+\")\n",
        "    else:\n",
        "      prompts= [audio, prompt]\n",
        "      if debug: print(\"First prompt\")\n",
        "\n",
        "    response = model.generate_content(\n",
        "        contents=prompts,\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=False,\n",
        "    )\n",
        "\n",
        "    finish_reason = response.candidates[0].finish_reason\n",
        "\n",
        "    if finish_reason == FinishReason.RECITATION \\\n",
        "    or finish_reason == FinishReason.PROHIBITED_CONTENT:\n",
        "        print(finish_reason, end=\"\\n\")\n",
        "        continue\n",
        "    try:\n",
        "        value = response.candidates[0].text\n",
        "        value = response.text\n",
        "        if debug: print(value, end=\"\\n\")\n",
        "\n",
        "        value = value.replace(\"```tsv\", \"\").replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "\n",
        "        result.append(value #+ \" \"\n",
        "        )\n",
        "\n",
        "    except (ValueError, AttributeError) as e:\n",
        "        print(\"ERROR get the result\")\n",
        "        print(e, end=\"\\n\")\n",
        "\n",
        "    if debug: print(finish_reason)\n",
        "\n",
        "    if finish_reason != FinishReason.MAX_TOKENS :\n",
        "        isFinished = True\n",
        "        if debug: print(\"isFinished\")\n",
        "        break\n",
        "\n",
        "  if debug: print(\"Done\")\n",
        "  return \"\".join(result)\n",
        "\n",
        "\n",
        "@retry.Retry(timeout=3000.0)\n",
        "def transcribe_with_gemini_data(prompt, data=None, mime_type=\"audio/wav\", model_name=None, top_p=0.0):\n",
        "\n",
        "  audio1 = Part.from_data(data,\n",
        "        mime_type=mime_type)\n",
        "\n",
        "  return transcribe_with_gemini_from_part(prompt, audio1, model_name, top_p)\n",
        "\n",
        "@retry.Retry(timeout=3000.0)\n",
        "def transcribe_with_gemini_from_uri(prompt, audio_path, mime_type=\"audio/wav\", model_name=None, top_p=0.0):\n",
        "\n",
        "  audio1 = Part.from_uri(\n",
        "    mime_type=mime_type,\n",
        "    uri=audio_path)\n",
        "\n",
        "  return transcribe_with_gemini_from_part(prompt, audio1, model_name, top_p)\n",
        "\n",
        "if debug:\n",
        "  uri=wav_files[0]\n",
        "  result = transcribe_with_gemini_from_uri(prompt, audio_path=uri, model_name=\"gemini-1.5-flash\")\n",
        "  print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 8,
          "status": "ok",
          "timestamp": 1727383490859,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "mWYnm_NjWmvs",
        "outputId": "72ba2b7b-500f-4a2b-d82d-1e5a1051b15c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW4v5lbBVlD1"
      },
      "source": [
        "## Strategy split by silence\n",
        " - Truncate the audio file in segment to avoid the max output token finish raison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1727383490860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "a5e75PnInT06"
      },
      "outputs": [],
      "source": [
        "# utils function to truncate audio file\n",
        "import io\n",
        "from pydub import AudioSegment\n",
        "\n",
        "root_dir = '.'\n",
        "output_dir = '.'\n",
        "\n",
        "\n",
        "def splitAudio(root_dir, file, start, stop, output_dir):\n",
        "    sound = AudioSegment.from_mp3(root_dir+file)\n",
        "\n",
        "    sound = sound[start:stop]\n",
        "    if debug:\n",
        "      print(f\"file = {file}\")\n",
        "      print(f\"duration_seconds = {sound.duration_seconds}\")\n",
        "      print(f\"sample_width = {sound.sample_width}\")\n",
        "      print(f\"channels = {sound.channels}\")\n",
        "      print(f\"frame_rate = {sound.frame_rate}\")\n",
        "\n",
        "    file_segment = output_dir+file+f\"-{start}-{stop}.wav\"\n",
        "\n",
        "    sound.export(file_segment, format=\"wav\")\n",
        "    return file_segment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1727383490860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "iBZFyZW8p6-I"
      },
      "outputs": [],
      "source": [
        "# generate sequence from audio file split by silences\n",
        "def get_audio_sequence_split_by_silences(file, min_silence_len=500):\n",
        "    from pydub import AudioSegment, silence\n",
        "\n",
        "    myaudio = AudioSegment.from_mp3(file)\n",
        "    dBFS=myaudio.dBFS\n",
        "\n",
        "    min_silence_len = 600\n",
        "    max_silence_len = 59000\n",
        "    speak_sequences = silence.detect_nonsilent(myaudio, min_silence_len=min_silence_len, silence_thresh=dBFS-20, seek_step=10)\n",
        "\n",
        "    # filter speak_sequences when stop - start are more than 59 secondes\n",
        "    speak_sequences_too_big = [(start, stop) for start, stop in speak_sequences if stop - start > max_silence_len]\n",
        "\n",
        "    while(len(speak_sequences_too_big) > 0 and min_silence_len >=100 ):\n",
        "\n",
        "      min_silence_len =     min (min_silence_len-100, 100)\n",
        "      speak_sequences = silence.detect_nonsilent(myaudio, min_silence_len=min_silence_len, silence_thresh=dBFS-20, seek_step=10)\n",
        "\n",
        "      # filter speak_sequences when stop - start are more than 59 secondes\n",
        "      speak_sequences_too_big = [(start, stop) for start, stop in speak_sequences if stop - start > max_silence_len]\n",
        "      print(\"Sequence more than 59s : \", len(speak_sequences_too_big))\n",
        "      print(f\"min_silence_len = {min_silence_len}\")\n",
        "\n",
        "    return speak_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1727383490860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "CutlB8vDqE2Q",
        "outputId": "53132f61-64d8-4ec2-de07-d6caa073c230"
      },
      "outputs": [],
      "source": [
        "# generate sequence from audio file split by hard split defined by the increment variable\n",
        "def get_audio_sequence_hard_split(file,     INCREMENT = 59*1000):\n",
        "    from pydub import AudioSegment\n",
        "    import math\n",
        "\n",
        "    sound = AudioSegment.from_mp3(file)\n",
        "\n",
        "    if debug: print(f\"duration_seconds = {sound.duration_seconds}\")\n",
        "    duration_ms =  math.ceil(sound.duration_seconds * 1000)\n",
        "    if debug: print(f\"duration_ms = {duration_ms}\")\n",
        "    return [(start, min(start + INCREMENT, duration_ms))\n",
        "            for start in range(0, duration_ms, INCREMENT)]\n",
        "\n",
        "\n",
        "# generate one full sequence from audio file\n",
        "def get_one_full_sequence(file):\n",
        "    from pydub import AudioSegment, silence\n",
        "    import math\n",
        "\n",
        "    sound = AudioSegment.from_mp3(file)\n",
        "\n",
        "    if debug: print(f\"duration_seconds = {sound.duration_seconds}\")\n",
        "    #duration_ms = sound.duration_seconds * 1000\n",
        "\n",
        "    duration_ms =  math.ceil(sound.duration_seconds * 1000)\n",
        "    if debug: print(f\"duration_ms = {duration_ms}\")\n",
        "\n",
        "    return [(0, duration_ms)]\n",
        "\n",
        "if debug:\n",
        "  get_audio_sequence_hard_split(\"1-temp.wav\")\n",
        "  get_one_full_sequence(\"1-temp.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1727383490860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "MLm-dM8Cnhlg"
      },
      "outputs": [],
      "source": [
        "# Process a file with a prompt and gemini model apply to the _stt function in parameter\n",
        "def process_local_file_by_chunk(file_name, _stt, _split_sequence_strategy, prompt, model_name):\n",
        "\n",
        "    sound = AudioSegment.from_mp3(file_name )\n",
        "    if debug:\n",
        "      print(f\"duration_seconds = {sound.duration_seconds}\")\n",
        "      print(f\"sample_width = {sound.sample_width}\")\n",
        "      print(f\"channels = {sound.channels}\")\n",
        "      print(f\"frame_rate = {sound.frame_rate}\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    speak_sequences = _split_sequence_strategy(file_name)\n",
        "    for (start, stop) in speak_sequences:\n",
        "\n",
        "        buffer = io.BytesIO()\n",
        "\n",
        "        sound[start:stop].export(buffer, format=\"wav\" )\n",
        "        batch_result = _stt(data = buffer.read(), prompt=prompt, model_name=model_name)\n",
        "        batch_result = \"\".join(batch_result)\n",
        "\n",
        "        print(f\"start = {start} - stop = {stop}\")\n",
        "\n",
        "        results.extend(batch_result+\" \")\n",
        "\n",
        "\n",
        "    return \"\".join(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1727383490860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "oWr-l-KSVwAl"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "def gemini_stt(data, prompt, model_name, uri=None):\n",
        "  return transcribe_with_gemini_data(data=data, prompt=prompt, model_name=model_name)\n",
        "\n",
        "def gemini_stt_gcs(uri, prompt, model_name, data=None):\n",
        "  return transcribe_with_gemini_from_uri(audio_path=uri, prompt=prompt, model_name=model_name)\n",
        "\n",
        "def process_transcriptions(prompt, split_strategies_dic,models_dic, audio_extention = '.wav'):\n",
        "\n",
        "  for split_strategy in split_strategies_dic:\n",
        "    if debug: print(f\"Split strategy: {split_strategy}\")\n",
        "\n",
        "    for model_name in models_dic:\n",
        "      if debug: print(f\"Model: {model_name}\")\n",
        "      text_files = [string.replace(audio_extention, '.txt') for string in wav_files]\n",
        "      wav_text_arr = zip(wav_files, text_files)\n",
        "\n",
        "      i = 0\n",
        "      for wav_file, text_file in wav_text_arr:\n",
        "        if debug: print(f\"Processing {i}\")\n",
        "        # Store text file locally\n",
        "        bucket, file_txt = split_gcs_uri(text_file)\n",
        "        local_file_txt = f\"{i}-ground-truth.txt\"\n",
        "        store_temp_file_from_gcs(bucket, file_txt, local_file_txt)\n",
        "\n",
        "        _split_strategy = split_strategies_dic[split_strategy]\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        if _split_strategy is not None:\n",
        "          # Store local audio file locally\n",
        "          bucket, file_wav = split_gcs_uri(wav_file)\n",
        "          local_file = f\"{i}-temp{audio_extention}\"\n",
        "          store_temp_file_from_gcs(bucket, file_wav, local_file)\n",
        "\n",
        "          result = process_local_file_by_chunk(local_file,\n",
        "                                _stt=models_dic[model_name],\n",
        "                                _split_sequence_strategy=split_strategies_dic[split_strategy],\n",
        "                                prompt=prompt,\n",
        "                                model_name=model_name)\n",
        "        else:\n",
        "          result = transcribe_with_gemini_from_uri(audio_path=wav_file, prompt=prompt, model_name=model_name)\n",
        "\n",
        "        end_time = time.perf_counter()\n",
        "        elapsed_time = end_time - start_time\n",
        "\n",
        "        if debug: print(f\"Elapsed time: {elapsed_time} seconds\")\n",
        "        if not \"gemini\" in model_name :\n",
        "          model_id = model_name.split(\"/\")[-1]\n",
        "        else:\n",
        "          model_id = model_name\n",
        "\n",
        "        gemini_file = f\"{i}-gemini_{split_strategy}_{model_id}_result.txt\"\n",
        "\n",
        "        with open(gemini_file, \"w\", encoding=\"UTF8\") as f:\n",
        "            f.write(result)\n",
        "\n",
        "        tags = { \"model_name\": model_name,\n",
        "                \"file\": wav_file,\n",
        "                \"ground-truth\": file_txt,\n",
        "                }\n",
        "\n",
        "        #TODO: #FixMe ugly specific code\n",
        "        write_file_to_gcs(bucket,  text_file.replace(\"stt_synthetic_tests_data\", \"stt_synthetic_results\").replace(\".txt\",\"\") + f\"-gemini_{split_strategy}_{model_id}.txt\",\n",
        "                          gemini_file, tags )\n",
        "\n",
        "        with open(local_file_txt, 'r') as f:\n",
        "          ground_truth = f.read()\n",
        "        ground_truth = ground_truth.replace(\"\\n\", \" \")\n",
        "\n",
        "        wer, semantic_textual_similarity = evaluate_data([result], [ground_truth])\n",
        "        if debug: print(f\"Results:{wav_file}, WER: {wer}, semantic_textual_similarity: {semantic_textual_similarity}\")\n",
        "\n",
        "        if system_instruction:\n",
        "          prompt_log = \"system_instruction:\" + system_instruction + \"\\nprompt:\" +prompt\n",
        "        else:\n",
        "          prompt_log = prompt\n",
        "\n",
        "        data = {\n",
        "          \"input_file\": wav_file,\n",
        "          \"ground_truth\": ground_truth,\n",
        "          \"model_name\": split_strategy+model_name,\n",
        "          \"prompt\": prompt_log,\n",
        "          \"wer\": wer,\n",
        "          \"processing_time\": elapsed_time,\n",
        "          \"semantic_textual_similarity\": semantic_textual_similarity,\n",
        "          \"generated_file\": gemini_file,\n",
        "          \"generated_text\": result\n",
        "        }\n",
        "        \n",
        "        df = pd.DataFrame( data = [data], columns = [\"input_file\",\"ground_truth\", \"wer\", \"semantic_textual_similarity\",\"generated_file\",\"generated_text\" , \"model_name\", \"prompt\", \"processing_time\"])\n",
        "\n",
        "        save_results_df_bq(df, table_id, truncate=False)\n",
        "\n",
        "        i += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "elapsed": 121907,
          "status": "ok",
          "timestamp": 1727397974483,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "46m6unH9CWC2",
        "outputId": "5466bbde-ecc1-4f5a-b1a9-f3e1b608e2e9"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "models_dic = {\n",
        "  \"gemini-1.5-pro\": gemini_stt,\n",
        "  \"gemini-1.5-pro-001\": gemini_stt,\n",
        "  \"gemini-1.5-pro-002\": gemini_stt,\n",
        "  \"gemini-1.5-flash-002\": gemini_stt,\n",
        "  \"gemini-1.5-flash\": gemini_stt,\n",
        "  # Finetuned model\n",
        "  \"projects/801452371447/locations/us-central1/endpoints/3103157164630343680\": gemini_stt,\n",
        "}\n",
        "\n",
        "split_strategies_dic = {\n",
        "\n",
        "  \"no_split:\"         : get_one_full_sequence,\n",
        "  \"gcs_max_token:\"    : None,\n",
        "  \"split_by_silences:\": get_audio_sequence_split_by_silences,\n",
        "  \"hard_split:\"       : get_audio_sequence_hard_split,\n",
        "}\n",
        "\n",
        "process_transcriptions(prompt, split_strategies_dic, models_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1727397974484,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "ig-Lnrnp7RXU",
        "outputId": "8a391579-fd7b-4b1d-b6f2-b96f1b5accd7"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "system_instruction = \"\"\"<ai_role>\n",
        "  You are an AI transcriptionist specializing in interviews.\n",
        "  Your primary function is to convert spoken language from audio files into accurate, well-formatted text. Audio files are in french, transcriptions are in french.\n",
        "  Ensure the transcribed text is clear and readable.\n",
        "  Add ponctuation like comma, question mark, exclamation mark, etc.\n",
        "  Ignore background audio.\n",
        "</ai_role>\n",
        "<answer_format>\n",
        "Output full word only.\n",
        "Do not generate any other text.\n",
        "Do not truncate words.\n",
        "</answer_format>\n",
        "\"\"\"\n",
        "\n",
        "prompt = \"\"\"Generate a transcription in French of the audio, only extract speech and ignore background audio.\n",
        "Transcribe spoken words.\n",
        "\"\"\"\n",
        "\n",
        "models_dic = {\n",
        "  \"gemini-1.5-pro\": gemini_stt,\n",
        "  \"gemini-1.5-pro-001\": gemini_stt,\n",
        "  \"gemini-1.5-pro-002\": gemini_stt,\n",
        "  \"gemini-1.5-flash-002\": gemini_stt,\n",
        "  \"gemini-1.5-flash\": gemini_stt,\n",
        "  # Finetuned model\n",
        "  \"projects/801452371447/locations/us-central1/endpoints/3103157164630343680\": gemini_stt,\n",
        "}\n",
        "\n",
        "split_strategies_dic = {\n",
        "\n",
        "  \"no_split:\"         : get_one_full_sequence,\n",
        "  \"gcs_max_token:\"    : None,\n",
        "  \"split_by_silences:\": get_audio_sequence_split_by_silences,\n",
        "  \"hard_split:\"       : get_audio_sequence_hard_split,\n",
        "}\n",
        "\n",
        "process_transcriptions(prompt)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "STT gemini benchmark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
