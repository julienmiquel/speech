{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EJDGpMcDWXQ"
      },
      "source": [
        "## Gemini STT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQgRX3XmCRTM"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade datasets nltk evaluate tokenizers seqeval sequence-evaluate sentence-transformers rouge jiwer google-cloud-aiplatform google-cloud-aiplatform[all] google-cloud-speech librosa jiwer protobuf pydub  google-cloud-storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROJECT_ID = \"ml-demo-384110\"  # @param {type:\"string\"}\n",
        "\n",
        "BUCKET_NAME = \"ml-demo-eu\" # @param {type:\"string\"}\n",
        "REGION = \"us-central1\" # @param {type:\"string\"}\n",
        "\n",
        "debug = True  # @param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "executionInfo": {
          "elapsed": 308,
          "status": "ok",
          "timestamp": 1727383481769,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "iZNQS1fKz_mY"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from google.api_core import retry\n",
        "import datetime\n",
        "import os\n",
        "import json\n",
        "import base64\n",
        "\n",
        "from vertexai.preview.generative_models import GenerativeModel\n",
        "from vertexai.generative_models import (\n",
        "    GenerativeModel,\n",
        "    HarmCategory,\n",
        "    HarmBlockThreshold,\n",
        "    Part,\n",
        "    SafetySetting,\n",
        "    FinishReason\n",
        ")\n",
        "from vertexai.preview import caching\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## List of podcast to transcribe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 2383,
          "status": "ok",
          "timestamp": 1727383487032,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "_r_TI3FguZu-"
      },
      "outputs": [],
      "source": [
        "# French great podcast \n",
        "!wget https://audio.audiomeans.fr/file/eiYNOubrDD/65beb744-01fc-40e2-8bb0-312c16855cbb.mp3 \n",
        "#!wget https://stitcher2.acast.com/livestitches/dda955d63d34fd840dbcbc7ecbd62c8e.mp3?aid=656e132f6a813000120f0beb&chid=6526f2efe61f1e0013a70f14&ci=HqtnuHv_UPnPPRIAlxniUe08dEp5lz1SwSazcaoaVPl1gSFlBMDkRQ%3D%3D&pf=rss&range=bytes%3D0-&sv=sphinx%401.220.1&uid=8f4b4d942da660c221023c27fcd9f4cc\n",
        "!mv *.mp3 ../assets/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvFIl1I7Wvlv"
      },
      "source": [
        "## Code Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz79wz9HW1Iv"
      },
      "source": [
        "### GCS code utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1727383487032,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "kUCqhV8TwzSC"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "import re\n",
        "\n",
        "def split_gcs_uri(gcs_uri):\n",
        "  \"\"\"Splits a GCS URI into bucket name and blob path variables.\n",
        "\n",
        "  Args:\n",
        "    gcs_uri: The GCS URI to split.\n",
        "\n",
        "  Returns:\n",
        "    A tuple containing the bucket name and blob path.\n",
        "  \"\"\"\n",
        "\n",
        "  match = re.match(r\"gs://([^/]+)/(.+)\", gcs_uri)\n",
        "  if match:\n",
        "    return match.groups()\n",
        "  else:\n",
        "    raise ValueError(\"Invalid GCS URI: {}\".format(gcs_uri))\n",
        "\n",
        "def write_file_to_gcs(gcs_bucket_name,  gcs_file_name, local_file_path, tags = None, verbose= False):\n",
        "    \"\"\"Writes a local file to GCS.\n",
        "\n",
        "    Args:\n",
        "    local_file_path: The path to the local file to write to GCS.\n",
        "    gcs_bucket_name: The name of the GCS bucket to write the file to.\n",
        "    gcs_file_name: The name of the GCS file to write the file to.\n",
        "\n",
        "    Returns:\n",
        "    The GCS file path.\n",
        "    \"\"\"\n",
        "    if verbose: print(f\"local_file_path = {local_file_path} - gcs_bucket_name = {gcs_bucket_name} - gcs_file_name = {gcs_file_name}\")\n",
        "    storage_client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = storage_client.bucket(gcs_bucket_name)\n",
        "    blob = bucket.blob(gcs_file_name)\n",
        "    if tags is not None:\n",
        "        blob.metadata = tags\n",
        "\n",
        "    if verbose: print(f\"upload_from_filename : local_file_path = {local_file_path}\")\n",
        "    blob.upload_from_filename(local_file_path, )\n",
        "\n",
        "    return blob\n",
        "\n",
        "\n",
        "def store_temp_file_from_gcs(bucket_name, file_name, localfile):\n",
        "    import tempfile\n",
        "    import os\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(file_name)\n",
        "\n",
        "    bytes_data = blob.download_as_bytes()\n",
        "\n",
        "    # Create a temporary file.\n",
        "    # tempDir = tempfile.gettempdir()\n",
        "    tempDir = os.getcwd()\n",
        "\n",
        "    temp_path = os.path.join(tempDir, localfile)\n",
        "    # f, temp_path = tempfile.mkstemp()\n",
        "    fp = open(temp_path, 'bw')\n",
        "    fp.write(bytes_data)\n",
        "    fp.seek(0)\n",
        "\n",
        "\n",
        "    return temp_path\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from moviepy.editor import VideoFileClip, TextClip, ColorClip, AudioFileClip\n",
        "from pydub.utils import mediainfo\n",
        "\n",
        "\n",
        "\n",
        "def convert_to_video(audio_path, verbose=False):\n",
        "    audio_path_ext = audio_path.split(\".\")[-1]\n",
        "    output_filename = audio_path.replace(audio_path_ext, \"mp4\") \n",
        "    \n",
        "    if verbose:\n",
        "        print(mediainfo(audio_path))\n",
        "    \n",
        "    # Load audio clips\n",
        "    audio_clips = AudioFileClip(audio_path)\n",
        "    total_audio = audio_clips.duration \n",
        "    print(f\"total_audio = {total_audio}\")\n",
        "    video_clip = ColorClip(size=(1,1), color=(255,255,255) #, duration=total_audio\n",
        "                           )\n",
        "\n",
        "    # Combine and save the video\n",
        "    video_clip = video_clip.set_audio(audio_clips).set_duration(total_audio)\n",
        "    \n",
        "    #video_clip.set_duration(total_audio)\n",
        "    video_clip.write_videofile(\n",
        "        filename=output_filename, fps=1, codec=\"libx264\",\n",
        "                        bitrate=\"1k\", \n",
        "                        audio=True, audio_fps=16000,\n",
        "                        preset=\"medium\",\n",
        "                        audio_nbytes=4, audio_codec=\"libmp3lame\",\n",
        "                        audio_bitrate=\"128k\", audio_bufsize=2000,\n",
        "                        #temp_audiofile=None,\n",
        "                        rewrite_audio=False, remove_temp=True,\n",
        "                        write_logfile=False, verbose=True,\n",
        "                        #threads=None, \n",
        "                        #ffmpeg_params=None\n",
        "    )\n",
        "\n",
        "    return output_filename\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1727383488608,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "N1Sstf67OUNv"
      },
      "outputs": [],
      "source": [
        "## Prompts examples\n",
        "\n",
        "system_instruction = \"\"\"You are an AI transcriptionist specializing in interviews.\n",
        "Your primary function is to convert spoken language from audio files into accurate, well-formatted text.\n",
        "Focus on capturing the nuances of the conversation, including speaker identification, hesitations, and any relevant non-verbal cues.\n",
        "Ensure the transcribed text is clear, readable, and faithful to the original audio.\"\"\"\n",
        "\n",
        "system_instruction = \"\"\"<ai_role>\n",
        "  You are an AI transcriptionist specializing in interviews, working for a local newspaper, situated in France.\n",
        "  Your primary function is to convert spoken language from audio files into accurate, well-formatted text. Audio files are in french, transcriptions are in french.\n",
        "  Ensure the transcribed text is clear and readable.\n",
        "  Identify each persons with their name and their genre if possible.\n",
        "  Ignore background audio.\n",
        "</ai_role>\n",
        "<answer_format>\n",
        "  Tab-separated values: Records are separated by newlines, and values within a record are separated by tab characters.\n",
        "  5 Columns generated: speaker, speaker_name, time_start, time_stop, text. Don't generate column headers.\n",
        "  speaker is the speaker id, speaker_name is the name of the speaker.\n",
        "  time_start and time_stop are the full time in seconds and not truncated.\n",
        "  text is the text of the speaker.\n",
        "  Since the values in the TSV format cannot contain literal tabs or newline characters, perform the following escapes in the text column:\n",
        "  escape sequence\tmeaning\n",
        "  \\n\tline feed\n",
        "  \\t\ttab\n",
        "  \\r\tcarriage return\n",
        "  \\\\\tbackslash\n",
        "</answer_format>\n",
        "<example>\n",
        "Speaker_1 Bonjour comment allez-vous ?\n",
        "Speaker_2 Ca va très bien merci.\n",
        "</example>\n",
        "\"\"\"\n",
        "\n",
        "prompt_continue = \"\"\"<task>\n",
        "Continue transcribing Audio Interview from the previous result.\n",
        "Start processing the audio file from the previous generated text. Do not start from the beginning of the audio.\n",
        "Be carefull to continue the previous generation available between the following tags previous_result. Datas in previous_result are provided in TSV format.\n",
        "</task>\"\"\"\n",
        "\n",
        "## Tests V4\n",
        "system_instruction = \"\"\"<ai_role>\n",
        "  You are an AI transcriptionist specializing in interviews, working for a local newspaper, situated in France.\n",
        "  Your primary function is to convert spoken language from audio files into accurate, well-formatted text. Audio files are in french, transcriptions are in french.\n",
        "  Ensure the transcribed text is clear and readable.\n",
        "  Ignore background audio.\n",
        "</ai_role>\n",
        "<answer_format>\n",
        "Output text only.\n",
        "Do not generate any other text.\n",
        "Do not truncate words.\n",
        "</answer_format>\"\"\"\n",
        "\n",
        "system_instruction = \"\"\"<ai_role>\n",
        "  You are an AI transcriptionist specializing in interviews, working for a local newspaper, situated in France.\n",
        "  Your primary function is to convert spoken language from audio files into accurate, well-formatted text. Audio files are in french, transcriptions are in french.\n",
        "  Ensure the transcribed text is clear and readable.\n",
        "  Identify each persons with their name and their genre if possible.\n",
        "  Ignore background audio.\n",
        "</ai_role>\n",
        "<answer_format>\n",
        "  Tab-separated values: Records are separated by newlines, and values within a record are separated by tab characters.\n",
        "  3 Columns generated: time_start, speaker, text. Don't generate column headers.\n",
        "  speaker is the speaker id.\n",
        "  time_start is the full time in milliseconds and not truncated.\n",
        "  time_start is surrond with [time_start]\n",
        "  text is the text of the speaker.\n",
        "  Since the values in the TSV format cannot contain literal tabs or newline characters, perform the following escapes in the text column:\n",
        "  escape sequence\tmeaning\n",
        "  \\t\ttab\n",
        "  \\r\tcarriage return\n",
        "</answer_format>\n",
        "<example>\n",
        "time_start speaker  : text\n",
        "[0]\tSpeaker_1\t:\tSi la conscience est un produit du cerveau, qu'en est-il de la conscience d'un être qui n'a pas de cerveau, ou dont le cerveau est différent du nôtre ?\n",
        "[8816.0]\tSpeaker_2\t:\tC'est une question fascinante qui soulève des réflexions sur la nature de la conscience et la possibilité d'autres formes de vie intelligente.\n",
        "[16192.0]\tSpeaker_1\t:\tEn effet, c'est un sujet qui suscite beaucoup de questions.\n",
        "</example>\n",
        "\"\"\"\n",
        "\n",
        "system_instruction = \"\"\"<ai_role>\n",
        "  You are an AI transcriptionist specializing in interviews, working for a local newspaper, situated in France.\n",
        "  Your primary function is to convert spoken language from audio files into accurate, well-formatted text. Audio files are in french, transcriptions are in french.\n",
        "  Ensure the transcribed text is clear and readable.\n",
        "  Add ponctuation like comma, question mark, exclamation mark, etc.\n",
        "  Ignore background audio.\n",
        "</ai_role>\n",
        "<answer_format>\n",
        "Output text only.\n",
        "Do not generate any other text.\n",
        "Do not truncate words.\n",
        "</answer_format>\n",
        "\n",
        "\"\"\"\n",
        "system_instruction = None\n",
        "\n",
        "\n",
        "\n",
        "prompt = \"\"\"Generate transcription for this interview in French.\n",
        "Ignore background audio.\n",
        "Transcribe in French.\n",
        "If you can infer the speaker name, please do. If not, use speaker_1, speaker_2, etc.\n",
        "\n",
        "Ouput format exammple:\n",
        "Speaker_1:Bonjour ! Je m'appelle Bob. Et vous, comment vous appelez-vous ?\n",
        "Speaker_2:Bonjour Bob !  Enchanté de faire votre connaissance.  Je m'appelle Morane.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt = \"\"\"Generate a transcription in French of the audio, only extract speech and ignore background audio.\n",
        "Transcribe spoken words.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euKtggj2VdRR"
      },
      "source": [
        "## Strategy generate results and wait to reach the max_token finish reason"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2253,
          "status": "ok",
          "timestamp": 1727383490859,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "_opTU8Bitu5P",
        "outputId": "abbd6c55-115b-450e-f0d9-e789a5c56ed9"
      },
      "outputs": [],
      "source": [
        "# Get transcription with max token strategy\n",
        "# Wait to reach the max output token finish raison and ask to continue generation from a prompt_continue prompt\n",
        "\n",
        "\n",
        "# This code process a part object (from uri or data)\n",
        "# if it reach the max_token limit, a continue_prompt is apply to continue the generation\n",
        "@retry.Retry(timeout=3000.0)\n",
        "def transcribe_with_gemini_from_part(prompt, audio, model_name, top_p):\n",
        "\n",
        "  result = []\n",
        "\n",
        "  if system_instruction is not None:\n",
        "    model = GenerativeModel(\n",
        "        model_name,\n",
        "        system_instruction=[system_instruction]\n",
        "    )\n",
        "  else:\n",
        "    model = GenerativeModel(model_name)\n",
        "\n",
        "  generation_config = {\n",
        "      \"max_output_tokens\": 8192,\n",
        "      \"temperature\": 0.0,\n",
        "      \"top_p\": top_p,\n",
        "  }\n",
        "  safety_settings={\n",
        "            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "      }\n",
        "\n",
        "\n",
        "  isFinished = False\n",
        "\n",
        "  while (isFinished == False):\n",
        "    if debug: print(\"Generating...\")\n",
        "\n",
        "    if len(result) > 0:\n",
        "      previous_text = \"\".join(result)\n",
        "      if debug: print(previous_text)\n",
        "\n",
        "      prompts = [audio, prompt_continue, previous_text]\n",
        "      if debug: print(80*\"*+\")\n",
        "    else:\n",
        "      prompts= [audio, prompt]\n",
        "      if debug: print(\"First prompt\")\n",
        "\n",
        "    response = model.generate_content(\n",
        "        contents=prompts,\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=False,\n",
        "    )\n",
        "\n",
        "    finish_reason = response.candidates[0].finish_reason\n",
        "\n",
        "    if finish_reason == FinishReason.RECITATION \\\n",
        "    or finish_reason == FinishReason.PROHIBITED_CONTENT:\n",
        "        print(finish_reason, end=\"\\n\")\n",
        "        continue\n",
        "    try:\n",
        "        value = response.candidates[0].text\n",
        "        value = response.text\n",
        "        if debug: print(value, end=\"\\n\")\n",
        "\n",
        "        value = value.replace(\"```tsv\", \"\").replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "\n",
        "        result.append(value #+ \" \"\n",
        "        )\n",
        "\n",
        "    except (ValueError, AttributeError) as e:\n",
        "        print(\"ERROR get the result\")\n",
        "        print(e, end=\"\\n\")\n",
        "\n",
        "    if debug: print(finish_reason)\n",
        "\n",
        "    if finish_reason != FinishReason.MAX_TOKENS :\n",
        "        isFinished = True\n",
        "        if debug: print(\"isFinished\")\n",
        "        break\n",
        "\n",
        "  if debug: print(\"Done\")\n",
        "  return \"\".join(result)\n",
        "\n",
        "\n",
        "@retry.Retry(timeout=3000.0)\n",
        "def transcribe_with_gemini_data(prompt, data=None, mime_type=\"audio/wav\", model_name=None, top_p=0.0):\n",
        "\n",
        "  audio1 = Part.from_data(data,\n",
        "        mime_type=mime_type)\n",
        "\n",
        "  return transcribe_with_gemini_from_part(prompt, audio1, model_name, top_p)\n",
        "\n",
        "@retry.Retry(timeout=3000.0)\n",
        "def transcribe_with_gemini_from_uri(prompt, audio_path, mime_type=\"audio/wav\", model_name=None, top_p=0.0):\n",
        "\n",
        "  audio1 = Part.from_uri(\n",
        "    mime_type=mime_type,\n",
        "    uri=audio_path)\n",
        "\n",
        "  return transcribe_with_gemini_from_part(prompt, audio1, model_name, top_p)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tests ASR with max_token strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Audio, display\n",
        "from ipywidgets import widgets\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "root_dir = \"../assets/\"\n",
        "# Get a list of all mp3 files in the current folder\n",
        "mp3_files = glob.glob(root_dir=root_dir, pathname=\n",
        "                    \"*.mp3\")             \n",
        "\n",
        "# create an array of Audio objects from the list of file paths\n",
        "audio = [Audio(filename=root_dir+mp3, element_id=mp3) for mp3 in mp3_files]\n",
        "# # # Iterate over each mp3 files\n",
        "for mp3_file in mp3_files:\n",
        "    print(root_dir+mp3_file)\n",
        "    display(Audio(root_dir+mp3_file))\n",
        "    \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load mp3 files in assets folder and generate ASR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 8,
          "status": "ok",
          "timestamp": 1727383490859,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "mWYnm_NjWmvs",
        "outputId": "72ba2b7b-500f-4a2b-d82d-1e5a1051b15c"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "import glob\n",
        "\n",
        "root_dir = \"../assets/\"\n",
        "# Get a list of all TSV files in the current folder\n",
        "mp3_files = glob.glob(root_dir=root_dir, pathname=\n",
        "                    \"*.mp3\")             \n",
        "\n",
        "prompt = \"\"\"Generate a transcription in French of the audio, only extract speech and ignore background audio.\n",
        "Transcribe spoken words.\n",
        "\"\"\"\n",
        "\n",
        "prompt_continue = \"\"\"<task>\n",
        "Continue transcribing audio data from the previous result.\n",
        "Start processing the audio file from the previous generated text. Do not start from the beginning of the audio.\n",
        "Be carefull to continue the previous generation available between the following tags previous_result. Datas in previous_result are provided in TSV format.\n",
        "</task>\"\"\"\n",
        "\n",
        "# Iterate over each mp3 files\n",
        "for mp3_file in mp3_files:\n",
        "    print(mp3_file)\n",
        "    with open(root_dir + mp3_file, \"rb\") as f:\n",
        "        # Load file bytes\n",
        "        asr_result =transcribe_with_gemini_data(prompt, data=f.read(), mime_type=\"audio/mp3\", model_name=\"gemini-1.5-pro-002\", top_p=0.0)\n",
        "        print(asr_result)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Add diarization and timestamps in the prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "import glob\n",
        "\n",
        "root_dir = \"../assets/\"\n",
        "# Get a list of all TSV files in the current folder\n",
        "mp3_files = glob.glob(root_dir=root_dir, pathname=\n",
        "                    \"*.mp3\")             \n",
        "\n",
        "prompt = \"\"\"<ai_role>\n",
        "  You are an AI transcriptionist specializing in interviews, working for a local newspaper, situated in France.\n",
        "  Your primary function is to convert spoken language from audio files into accurate, well-formatted text. Audio files are in french, transcriptions are in french.\n",
        "  Ensure the transcribed text is clear and readable.\n",
        "  Identify each persons with their name and their genre if possible.\n",
        "  Ignore background audio.\n",
        "</ai_role>\n",
        "<answer_format>\n",
        "  Tab-separated values: Records are separated by newlines, and values within a record are separated by tab characters.\n",
        "  3 Columns generated: time_start, speaker, text. Don't generate column headers.\n",
        "  speaker is the speaker id.\n",
        "  time_start is the full time in milliseconds and not truncated.\n",
        "  time_start is surrond with [time_start]\n",
        "  text is the text of the speaker.\n",
        "  Since the values in the TSV format cannot contain literal tabs or newline characters, perform the following escapes in the text column:\n",
        "  escape sequence\tmeaning\n",
        "  \\t\ttab\n",
        "  \\r\tcarriage return\n",
        "</answer_format>\n",
        "<example>\n",
        "time_start speaker  : text\n",
        "[0]\tSpeaker_1\t:\tSi la conscience est un produit du cerveau, qu'en est-il de la conscience d'un être qui n'a pas de cerveau, ou dont le cerveau est différent du nôtre ?\n",
        "[8816.0]\tSpeaker_2\t:\tC'est une question fascinante qui soulève des réflexions sur la nature de la conscience et la possibilité d'autres formes de vie intelligente.\n",
        "[16192.0]\tSpeaker_1\t:\tEn effet, c'est un sujet qui suscite beaucoup de questions.\n",
        "</example>\n",
        "\"\"\"\n",
        "\n",
        "# Iterate over each mp3 files\n",
        "for mp3_file in mp3_files:\n",
        "    print(mp3_file)\n",
        "    with open(root_dir + mp3_file, \"rb\") as f:\n",
        "        # Load file bytes\n",
        "        asr_result =transcribe_with_gemini_data(prompt, data=f.read(), mime_type=\"audio/mp3\", model_name=\"gemini-1.5-pro-002\", top_p=0.0)\n",
        "        print(asr_result)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert file before call gemini to get more accurate timecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "root_dir = \"../assets/\"\n",
        "# Get a list of all TSV files in the current folder\n",
        "mp3_files = glob.glob(root_dir=root_dir, pathname=\n",
        "                    \"*.mp3\")             \n",
        "\n",
        "# Iterate over each mp3 files\n",
        "for mp3_file in mp3_files:\n",
        "    mp4_file = convert_to_video(root_dir+mp3_file)\n",
        "    with open(root_dir + mp4_file, \"rb\") as f:\n",
        "        # Load file bytes\n",
        "        transcribe_with_gemini_data(prompt, data=f.read(), mime_type=\"video/mp4\", model_name=\"gemini-1.5-pro-002\", top_p=0.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "\n",
        "root_dir = \"../assets/\"\n",
        "# Get a list of all TSV files in the current folder\n",
        "mp3_files = glob.glob(root_dir=root_dir, pathname=\n",
        "                    \"*.mp3\")             \n",
        "\n",
        "# Iterate over each mp3 files\n",
        "for mp3_file in mp3_files:\n",
        "    mp4_file = convert_to_video(root_dir+mp3_file)\n",
        "    with open(root_dir + mp4_file, \"rb\") as f:\n",
        "        # Load file bytes\n",
        "        transcribe_with_gemini_data(prompt, data=f.read(), mime_type=\"video/mp4\", model_name=\"gemini-1.5-pro-002\", top_p=0.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"\"\"<ai_role>\n",
        "  You are an AI transcriptionist specializing in interviews, working for a local newspaper, situated in France.\n",
        "  Your primary function is to convert spoken language from audio files into accurate, well-formatted text. Audio files are in french, transcriptions are in french.\n",
        "  Ensure the transcribed text is clear and readable.\n",
        "  Identify each persons with their name and their genre if possible.\n",
        "  Ignore background audio.\n",
        "</ai_role>\n",
        "<answer_format>\n",
        "  Tab-separated values: Records are separated by newlines, and values within a record are separated by tab characters.\n",
        "  3 Columns generated: time_start, speaker, text. Don't generate column headers.\n",
        "  speaker is the speaker id.\n",
        "  time_start is the full time in seconds and not truncated.\n",
        "  time_start is surrond with [time_start]\n",
        "  text is the text of the speaker.\n",
        "  Since the values in the TSV format cannot contain literal tabs or newline characters, perform the following escapes in the text column:\n",
        "  escape sequence\tmeaning\n",
        "  \\t\ttab\n",
        "  \\r\tcarriage return\n",
        "</answer_format>\n",
        "<example>\n",
        "time_start speaker  : text\n",
        "[0]\tSpeaker_1\t:\tSi la conscience est un produit du cerveau, qu'en est-il de la conscience d'un être qui n'a pas de cerveau, ou dont le cerveau est différent du nôtre ?\n",
        "[8.816]\tSpeaker_2\t:\tC'est une question fascinante qui soulève des réflexions sur la nature de la conscience et la possibilité d'autres formes de vie intelligente.\n",
        "[16.192]\tSpeaker_1\t:\tEn effet, c'est un sujet qui suscite beaucoup de questions.\n",
        "</example>\n",
        "\"\"\"\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "root_dir = \"../assets/\"\n",
        "# Get a list of all TSV files in the current folder\n",
        "mp3_files = glob.glob(root_dir=root_dir, pathname=\n",
        "                    \"*.mp3\")             \n",
        "\n",
        "# Iterate over each mp3 files\n",
        "for mp3_file in mp3_files:\n",
        "    mp4_file = convert_to_video(root_dir+mp3_file)\n",
        "    with open(root_dir + mp4_file, \"rb\") as f:\n",
        "        # Load file bytes\n",
        "        transcribe_with_gemini_data(prompt, data=f.read(), mime_type=\"video/mp4\", model_name=\"gemini-1.5-pro-002\", top_p=0.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "import glob\n",
        "\n",
        "root_dir = \"../assets/\"\n",
        "# Get a list of all TSV files in the current folder\n",
        "mp3_files = glob.glob(root_dir=root_dir, pathname=\n",
        "                    \"*.mp3\")    \n",
        "\n",
        "audio_sample = AudioSegment.from_mp3(root_dir+mp3_files[0])\n",
        "duration_ms = audio_sample.duration_seconds*1000\n",
        "print(\"duration_ms= \" , duration_ms)\n",
        "# Verify \n",
        "audio_piece= audio_sample[1538800:1540000]\n",
        "\n",
        "audio_piece.export(\"test_clip.wav\", format='wav')\n",
        "from IPython.display import Audio, display\n",
        "display(Audio(filename=\"test_clip.wav\"))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mp3_files[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW4v5lbBVlD1"
      },
      "source": [
        "## Strategy split by silence\n",
        " - Truncate the audio file in segment to avoid the max output token finish raison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1727383490860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "a5e75PnInT06"
      },
      "outputs": [],
      "source": [
        "# utils function to truncate audio file\n",
        "import io\n",
        "from pydub import AudioSegment\n",
        "\n",
        "root_dir = '.'\n",
        "output_dir = '.'\n",
        "\n",
        "\n",
        "def splitAudio(root_dir, file, start, stop, output_dir):\n",
        "    sound = AudioSegment.from_mp3(root_dir+file)\n",
        "\n",
        "    sound = sound[start:stop]\n",
        "    if debug:\n",
        "      print(f\"file = {file}\")\n",
        "      print(f\"duration_seconds = {sound.duration_seconds}\")\n",
        "      print(f\"sample_width = {sound.sample_width}\")\n",
        "      print(f\"channels = {sound.channels}\")\n",
        "      print(f\"frame_rate = {sound.frame_rate}\")\n",
        "\n",
        "    file_segment = output_dir+file+f\"-{start}-{stop}.wav\"\n",
        "\n",
        "    sound.export(file_segment, format=\"wav\")\n",
        "    return file_segment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1727383490860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "iBZFyZW8p6-I"
      },
      "outputs": [],
      "source": [
        "# generate sequence from audio file split by silences\n",
        "def get_audio_sequence_split_by_silences(file, min_silence_len=500):\n",
        "    from pydub import AudioSegment, silence\n",
        "\n",
        "    myaudio = AudioSegment.from_mp3(file)\n",
        "    dBFS=myaudio.dBFS\n",
        "\n",
        "    min_silence_len = 600\n",
        "    max_silence_len = 59000\n",
        "    speak_sequences = silence.detect_nonsilent(myaudio, min_silence_len=min_silence_len, silence_thresh=dBFS-20, seek_step=10)\n",
        "\n",
        "    # filter speak_sequences when stop - start are more than 59 secondes\n",
        "    speak_sequences_too_big = [(start, stop) for start, stop in speak_sequences if stop - start > max_silence_len]\n",
        "\n",
        "    while(len(speak_sequences_too_big) > 0 and min_silence_len >=100 ):\n",
        "\n",
        "      min_silence_len =     min (min_silence_len-100, 100)\n",
        "      speak_sequences = silence.detect_nonsilent(myaudio, min_silence_len=min_silence_len, silence_thresh=dBFS-20, seek_step=10)\n",
        "\n",
        "      # filter speak_sequences when stop - start are more than 59 secondes\n",
        "      speak_sequences_too_big = [(start, stop) for start, stop in speak_sequences if stop - start > max_silence_len]\n",
        "      print(\"Sequence more than 59s : \", len(speak_sequences_too_big))\n",
        "      print(f\"min_silence_len = {min_silence_len}\")\n",
        "\n",
        "    return speak_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1727383490860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "CutlB8vDqE2Q",
        "outputId": "53132f61-64d8-4ec2-de07-d6caa073c230"
      },
      "outputs": [],
      "source": [
        "# generate sequence from audio file split by hard split defined by the increment variable\n",
        "def get_audio_sequence_hard_split(file,     INCREMENT = 59*1000):\n",
        "    from pydub import AudioSegment\n",
        "    import math\n",
        "\n",
        "    sound = AudioSegment.from_mp3(file)\n",
        "\n",
        "    if debug: print(f\"duration_seconds = {sound.duration_seconds}\")\n",
        "    duration_ms =  math.ceil(sound.duration_seconds * 1000)\n",
        "    if debug: print(f\"duration_ms = {duration_ms}\")\n",
        "    return [(start, min(start + INCREMENT, duration_ms))\n",
        "            for start in range(0, duration_ms, INCREMENT)]\n",
        "\n",
        "\n",
        "# generate one full sequence from audio file\n",
        "def get_one_full_sequence(file):\n",
        "    from pydub import AudioSegment, silence\n",
        "    import math\n",
        "\n",
        "    sound = AudioSegment.from_mp3(file)\n",
        "\n",
        "    if debug: print(f\"duration_seconds = {sound.duration_seconds}\")\n",
        "    #duration_ms = sound.duration_seconds * 1000\n",
        "\n",
        "    duration_ms =  math.ceil(sound.duration_seconds * 1000)\n",
        "    if debug: print(f\"duration_ms = {duration_ms}\")\n",
        "\n",
        "    return [(0, duration_ms)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1727383490860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "MLm-dM8Cnhlg"
      },
      "outputs": [],
      "source": [
        "# Process a file with a prompt and gemini model apply to the _stt function in parameter\n",
        "def process_local_file_by_chunk(file_name, _stt, _split_sequence_strategy, prompt, model_name):\n",
        "\n",
        "    sound = AudioSegment.from_mp3(file_name )\n",
        "    if debug:\n",
        "      print(f\"duration_seconds = {sound.duration_seconds}\")\n",
        "      print(f\"sample_width = {sound.sample_width}\")\n",
        "      print(f\"channels = {sound.channels}\")\n",
        "      print(f\"frame_rate = {sound.frame_rate}\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    speak_sequences = _split_sequence_strategy(file_name)\n",
        "    for (start, stop) in speak_sequences:\n",
        "\n",
        "        buffer = io.BytesIO()\n",
        "\n",
        "        sound[start:stop].export(buffer, format=\"wav\" )\n",
        "        batch_result = _stt(data = buffer.read(), prompt=prompt, model_name=model_name)\n",
        "        batch_result = \"\".join(batch_result)\n",
        "\n",
        "        print(f\"start = {start} - stop = {stop}\")\n",
        "\n",
        "        results.extend(batch_result+\" \")\n",
        "\n",
        "\n",
        "    return \"\".join(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1727383490860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "oWr-l-KSVwAl"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "def gemini_stt(data, prompt, model_name, uri=None):\n",
        "  return transcribe_with_gemini_data(data=data, prompt=prompt, model_name=model_name)\n",
        "\n",
        "def gemini_stt_gcs(uri, prompt, model_name, data=None):\n",
        "  return transcribe_with_gemini_from_uri(audio_path=uri, prompt=prompt, model_name=model_name)\n",
        "\n",
        "def process_transcriptions(prompt, split_strategies_dic,models_dic, audio_extention = '.wav'):\n",
        "\n",
        "\n",
        "  for split_strategy in split_strategies_dic:\n",
        "    if debug: print(f\"Split strategy: {split_strategy}\")\n",
        "\n",
        "    for model_name in models_dic:\n",
        "      if debug: print(f\"Model: {model_name}\")\n",
        "      mp3_files = glob.glob(root_dir=root_dir, pathname=\n",
        "                    \"*.mp3\")    \n",
        "\n",
        "\n",
        "      i = 0\n",
        "      for mp3_file in mp3_files:\n",
        "        if debug: print(f\"Processing {i}\")\n",
        "        mp4_file = convert_to_video(root_dir+mp3_file)\n",
        "\n",
        "        # Store text file locally\n",
        "        # bucket, file_txt = split_gcs_uri(text_file)\n",
        "        # local_file_txt = f\"{i}-ground-truth.txt\"\n",
        "        # store_temp_file_from_gcs(bucket, file_txt, local_file_txt)\n",
        "        local_file = root_dir+mp4_file\n",
        "        _split_strategy = split_strategies_dic[split_strategy]\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        if _split_strategy is not None:\n",
        "          # Store local audio file locally\n",
        "          # bucket, file_wav = split_gcs_uri(wav_file)\n",
        "          # local_file = f\"{i}-temp{audio_extention}\"\n",
        "          # store_temp_file_from_gcs(bucket, file_wav, local_file)\n",
        "\n",
        "          result = process_local_file_by_chunk(local_file,\n",
        "                                _stt=models_dic[model_name],\n",
        "                                _split_sequence_strategy=split_strategies_dic[split_strategy],\n",
        "                                prompt=prompt,\n",
        "                                model_name=model_name)\n",
        "        else:          \n",
        "          write_file_to_gcs(BUCKET_NAME, f\"podcasts/{local_file}\", local_file)\n",
        "          result = transcribe_with_gemini_from_uri(audio_path=f\"gs://{BUCKET_NAME}/podcasts/{local_file}\", prompt=prompt, model_name=model_name)\n",
        "\n",
        "        end_time = time.perf_counter()\n",
        "        elapsed_time = end_time - start_time\n",
        "\n",
        "        if debug: print(f\"Elapsed time: {elapsed_time} seconds\")\n",
        "        if not \"gemini\" in model_name :\n",
        "          model_id = model_name.split(\"/\")[-1]\n",
        "        else:\n",
        "          model_id = model_name\n",
        "\n",
        "        gemini_file = f\"{i}-gemini_{split_strategy}_{model_id}_result.txt\"\n",
        "\n",
        "        with open(gemini_file, \"w\", encoding=\"UTF8\") as f:\n",
        "            f.write(result)\n",
        "\n",
        "        # tags = { \"model_name\": model_name,\n",
        "        #         \"file\": wav_file,\n",
        "        #         \"ground-truth\": file_txt,\n",
        "        #         }\n",
        "\n",
        "        #TODO: #FixMe ugly specific code\n",
        "        # write_file_to_gcs(bucket,  text_file.replace(\"stt_synthetic_tests_data\", \"stt_synthetic_results\").replace(\".txt\",\"\") + f\"-gemini_{split_strategy}_{model_id}.txt\",\n",
        "        #                   gemini_file, tags )\n",
        "\n",
        "        # with open(local_file_txt, 'r') as f:\n",
        "        #   ground_truth = f.read()\n",
        "        # ground_truth = ground_truth.replace(\"\\n\", \" \")\n",
        "\n",
        "        # wer, semantic_textual_similarity = evaluate_data([result], [ground_truth])\n",
        "        # if debug: print(f\"Results:{wav_file}, WER: {wer}, semantic_textual_similarity: {semantic_textual_similarity}\")\n",
        "\n",
        "        # if system_instruction:\n",
        "        #   prompt_log = \"system_instruction:\" + system_instruction + \"\\nprompt:\" +prompt\n",
        "        # else:\n",
        "        #   prompt_log = prompt\n",
        "\n",
        "        # data = {\n",
        "        #   \"input_file\": wav_file,\n",
        "        #   \"ground_truth\": ground_truth,\n",
        "        #   \"model_name\": split_strategy+model_name,\n",
        "        #   \"prompt\": prompt_log,\n",
        "        #   \"wer\": wer,\n",
        "        #   \"processing_time\": elapsed_time,\n",
        "        #   \"semantic_textual_similarity\": semantic_textual_similarity,\n",
        "        #   \"generated_file\": gemini_file,\n",
        "        #   \"generated_text\": result\n",
        "        # }\n",
        "        \n",
        "        # df = pd.DataFrame( data = [data], columns = [\"input_file\",\"ground_truth\", \"wer\", \"semantic_textual_similarity\",\"generated_file\",\"generated_text\" , \"model_name\", \"prompt\", \"processing_time\"])\n",
        "\n",
        "        # save_results_df_bq(df, table_id, truncate=False)\n",
        "\n",
        "        i += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "elapsed": 121907,
          "status": "ok",
          "timestamp": 1727397974483,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "46m6unH9CWC2",
        "outputId": "5466bbde-ecc1-4f5a-b1a9-f3e1b608e2e9"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "models_dic = {\n",
        "  \"gemini-1.5-pro\": gemini_stt,\n",
        "  \"gemini-1.5-pro-001\": gemini_stt,\n",
        "  \"gemini-1.5-pro-002\": gemini_stt,\n",
        "  \"gemini-1.5-flash-002\": gemini_stt,\n",
        "  \"gemini-1.5-flash\": gemini_stt,\n",
        "  # Finetuned model\n",
        "  #\"projects/801452371447/locations/us-central1/endpoints/3103157164630343680\": gemini_stt,\n",
        "}\n",
        "\n",
        "split_strategies_dic = {\n",
        "  \"gcs_max_token:\"    : None,\n",
        "  \"split_by_silences:\": get_audio_sequence_split_by_silences,\n",
        "  \"hard_split:\"       : get_audio_sequence_hard_split,\n",
        "  # \"no_split:\"         : get_one_full_sequence,  \n",
        "}\n",
        "\n",
        "process_transcriptions(prompt, split_strategies_dic, models_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BUCKET_NAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1727397974484,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "ig-Lnrnp7RXU",
        "outputId": "8a391579-fd7b-4b1d-b6f2-b96f1b5accd7"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "system_instruction = \"\"\"<ai_role>\n",
        "  You are an AI transcriptionist specializing in interviews.\n",
        "  Your primary function is to convert spoken language from audio files into accurate, well-formatted text. Audio files are in french, transcriptions are in french.\n",
        "  Ensure the transcribed text is clear and readable.\n",
        "  Add ponctuation like comma, question mark, exclamation mark, etc.\n",
        "  Ignore background audio.\n",
        "</ai_role>\n",
        "<answer_format>\n",
        "Output full word only.\n",
        "Do not generate any other text.\n",
        "Do not truncate words.\n",
        "</answer_format>\n",
        "\"\"\"\n",
        "\n",
        "prompt = \"\"\"Generate a transcription in French of the audio, only extract speech and ignore background audio.\n",
        "Transcribe spoken words.\n",
        "\"\"\"\n",
        "\n",
        "models_dic = {\n",
        "  \"gemini-1.5-pro\": gemini_stt,\n",
        "  \"gemini-1.5-pro-001\": gemini_stt,\n",
        "  \"gemini-1.5-pro-002\": gemini_stt,\n",
        "  \"gemini-1.5-flash-002\": gemini_stt,\n",
        "  \"gemini-1.5-flash\": gemini_stt,\n",
        "  # Finetuned model\n",
        "  \"projects/801452371447/locations/us-central1/endpoints/3103157164630343680\": gemini_stt,\n",
        "}\n",
        "\n",
        "split_strategies_dic = {\n",
        "\n",
        "  \"no_split:\"         : get_one_full_sequence,\n",
        "  \"gcs_max_token:\"    : None,\n",
        "  \"split_by_silences:\": get_audio_sequence_split_by_silences,\n",
        "  \"hard_split:\"       : get_audio_sequence_hard_split,\n",
        "}\n",
        "\n",
        "process_transcriptions(prompt)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "STT gemini benchmark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
