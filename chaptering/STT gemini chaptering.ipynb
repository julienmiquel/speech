{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EJDGpMcDWXQ"
      },
      "source": [
        "## Gemini chaptering experiments\n",
        "* With this code I demonstrate how to do STT with different models\n",
        "* And generate chapter based on this transcript. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQgRX3XmCRTM"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade datasets nltk evaluate tokenizers seqeval sequence-evaluate sentence-transformers rouge jiwer pydub google-cloud-aiplatform google-cloud-aiplatform[all]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "executionInfo": {
          "elapsed": 308,
          "status": "ok",
          "timestamp": 1727383481769,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "iZNQS1fKz_mY"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"cloud-llm-preview1\"  # @param {type:\"string\"}\n",
        "\n",
        "BUCKET_NAME = \"julien-us\" # @param {type:\"string\"}\n",
        "REGION = \"us-central1\" # @param {type:\"string\"}\n",
        "BQ_REGION = \"us\" # @param {type:\"string\"}\n",
        "#table_id = \"julienmiquel_us.stt_v10\" # @param {type:\"string\"}\n",
        "\n",
        "debug = True  # @param {type:\"boolean\"}\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "from google.api_core import retry\n",
        "import datetime\n",
        "\n",
        "import os\n",
        "import json\n",
        "import base64\n",
        "import vertexai\n",
        "\n",
        "from vertexai.preview.generative_models import GenerativeModel\n",
        "from vertexai.generative_models import (\n",
        "    GenerativeModel,\n",
        "    HarmCategory,\n",
        "    HarmBlockThreshold,\n",
        "    Part,\n",
        "    SafetySetting,\n",
        "    FinishReason\n",
        ")\n",
        "from vertexai.preview import caching\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "executionInfo": {
          "elapsed": 2383,
          "status": "ok",
          "timestamp": 1727383487032,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "_r_TI3FguZu-"
      },
      "outputs": [],
      "source": [
        "wav_files = !gsutil ls gs://julien-us/stt_synthetic_tests_data/*.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1727383487032,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "bbSJjHGVu5ZT",
        "outputId": "13a29616-ed72-4f93-a793-c0134a2bf46b"
      },
      "outputs": [],
      "source": [
        "text_files = [string.replace('.wav', '.txt') for string in wav_files]\n",
        "\n",
        "wav_text_arr = zip(wav_files, text_files)\n",
        "len(wav_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvFIl1I7Wvlv"
      },
      "source": [
        "## Code Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz79wz9HW1Iv"
      },
      "source": [
        "### GCS code utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1727383487032,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "kUCqhV8TwzSC"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "import re\n",
        "\n",
        "def split_gcs_uri(gcs_uri):\n",
        "  \"\"\"Splits a GCS URI into bucket name and blob path variables.\n",
        "\n",
        "  Args:\n",
        "    gcs_uri: The GCS URI to split.\n",
        "\n",
        "  Returns:\n",
        "    A tuple containing the bucket name and blob path.\n",
        "  \"\"\"\n",
        "\n",
        "  match = re.match(r\"gs://([^/]+)/(.+)\", gcs_uri)\n",
        "  if match:\n",
        "    return match.groups()\n",
        "  else:\n",
        "    raise ValueError(\"Invalid GCS URI: {}\".format(gcs_uri))\n",
        "\n",
        "def write_file_to_gcs(gcs_bucket_name,  gcs_file_name, local_file_path, tags = None, verbose= False):\n",
        "    \"\"\"Writes a local file to GCS.\n",
        "\n",
        "    Args:\n",
        "    local_file_path: The path to the local file to write to GCS.\n",
        "    gcs_bucket_name: The name of the GCS bucket to write the file to.\n",
        "    gcs_file_name: The name of the GCS file to write the file to.\n",
        "\n",
        "    Returns:\n",
        "    The GCS file path.\n",
        "    \"\"\"\n",
        "    if verbose: print(f\"local_file_path = {local_file_path} - gcs_bucket_name = {gcs_bucket_name} - gcs_file_name = {gcs_file_name}\")\n",
        "    storage_client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = storage_client.bucket(gcs_bucket_name)\n",
        "    blob = bucket.blob(gcs_file_name)\n",
        "    if tags is not None:\n",
        "        blob.metadata = tags\n",
        "\n",
        "    if verbose: print(f\"upload_from_filename : local_file_path = {local_file_path}\")\n",
        "    blob.upload_from_filename(local_file_path, )\n",
        "\n",
        "    return blob\n",
        "\n",
        "\n",
        "def store_temp_file_from_gcs(bucket_name, file_name, localfile):\n",
        "    import tempfile\n",
        "    import os\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(file_name)\n",
        "\n",
        "    bytes_data = blob.download_as_bytes()\n",
        "\n",
        "    # Create a temporary file.\n",
        "    # tempDir = tempfile.gettempdir()\n",
        "    tempDir = os.getcwd()\n",
        "\n",
        "    temp_path = os.path.join(tempDir, localfile)\n",
        "    # f, temp_path = tempfile.mkstemp()\n",
        "    fp = open(temp_path, 'bw')\n",
        "    fp.write(bytes_data)\n",
        "    fp.seek(0)\n",
        "\n",
        "\n",
        "    return temp_path\n",
        "\n",
        "# Listen the first element in the dataset.\n",
        "if debug:\n",
        "  for wav_file, text_file in wav_text_arr:\n",
        "    bucket, file = split_gcs_uri(wav_file)\n",
        "    store_temp_file_from_gcs(bucket, file, \"temp.wav\")\n",
        "\n",
        "    break\n",
        "\n",
        "  # Needed imports\n",
        "  import numpy as np\n",
        "  from IPython.display import Audio\n",
        "  from scipy.io import wavfile\n",
        "\n",
        "  # Generate a player for mono sound\n",
        "  Audio(\"temp.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE6KOLyVWz_0"
      },
      "source": [
        "### Evaluate results with metrics\n",
        "- wer\n",
        "- semantic_textual_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1577,
          "status": "ok",
          "timestamp": 1727383488608,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "KK3KitNU0wRq",
        "outputId": "2c5dd21f-93e4-4958-cadf-6992ec5b43c9"
      },
      "outputs": [],
      "source": [
        "from seq_eval import SeqEval\n",
        "import evaluate\n",
        "\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "\n",
        "evaluator = SeqEval()\n",
        "\n",
        "def evaluate_data(predictions, references, verbose= False):\n",
        "    references = [x for x in references if x!= '']\n",
        "    predictions = [x for x in predictions if x!= '']\n",
        "\n",
        "    references = references\n",
        "    predictions = predictions\n",
        "\n",
        "    if len(references)!= len(predictions):\n",
        "\n",
        "        min_arr = min(len(references), len(references))\n",
        "        print(f\"Reduce size to {min_arr}\")\n",
        "        predictions = predictions[0:min_arr]\n",
        "        references = references[0:min_arr]\n",
        "\n",
        "\n",
        "    scores = evaluator.evaluate(predictions, references, verbose=verbose)\n",
        "\n",
        "    if verbose: print(scores)\n",
        "\n",
        "    wer = wer_metric.compute(references=references, predictions=predictions)\n",
        "    wer = round(100 * wer, 2)\n",
        "    print(\"WER:\", wer ,end='\\n')\n",
        "    print(\"semantic_textual_similarity:\",scores['semantic_textual_similarity'],end='\\n')\n",
        "    return wer, scores['semantic_textual_similarity']\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euKtggj2VdRR"
      },
      "source": [
        "## Strategy max_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2253,
          "status": "ok",
          "timestamp": 1727383490859,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "_opTU8Bitu5P",
        "outputId": "abbd6c55-115b-450e-f0d9-e789a5c56ed9"
      },
      "outputs": [],
      "source": [
        "# Get transcription with max token strategy\n",
        "# Wait to reach the max output token finish raison and ask to continue generation from a prompt_continue prompt\n",
        "\n",
        "\n",
        "# This code process a part object (from uri or data)\n",
        "# if it reach the max_token limit, a continue_prompt is apply to continue the generation\n",
        "@retry.Retry(timeout=3000.0)\n",
        "def transcribe_with_gemini_from_part(prompt, audio, model_name, top_p):\n",
        "\n",
        "  result = []\n",
        "\n",
        "  if system_instruction is not None:\n",
        "    model = GenerativeModel(\n",
        "        model_name,\n",
        "        system_instruction=[system_instruction]\n",
        "    )\n",
        "  else:\n",
        "    model = GenerativeModel(model_name)\n",
        "\n",
        "  generation_config = {\n",
        "      \"max_output_tokens\": 8192,\n",
        "      \"temperature\": 0.0,\n",
        "      \"top_p\": top_p,\n",
        "  }\n",
        "  safety_settings={\n",
        "            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "      }\n",
        "\n",
        "\n",
        "  isFinished = False\n",
        "\n",
        "  while (isFinished == False):\n",
        "    if debug: print(\"Generating...\")\n",
        "\n",
        "    if len(result) > 0:\n",
        "      previous_text = \"\".join(result)\n",
        "      if debug: print(previous_text)\n",
        "\n",
        "      prompts = [audio, prompt_continue]\n",
        "      if debug: print(80*\"*+\")\n",
        "    else:\n",
        "      prompts= [audio, prompt]\n",
        "      if debug: print(\"First prompt\")\n",
        "\n",
        "    response = model.generate_content(\n",
        "        contents=prompts,\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=False,\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    finish_reason = response.candidates[0].finish_reason\n",
        "\n",
        "    if finish_reason == FinishReason.RECITATION \\\n",
        "    or finish_reason == FinishReason.PROHIBITED_CONTENT:\n",
        "        print(finish_reason, end=\"\\n\")\n",
        "        continue\n",
        "    try:\n",
        "        value = response.candidates[0].text\n",
        "        value = response.text\n",
        "        if debug: print(value, end=\"\\n\")\n",
        "\n",
        "        value = value.replace(\"```tsv\", \"\").replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "\n",
        "        result.append(value #+ \" \"\n",
        "        )\n",
        "\n",
        "    except (ValueError, AttributeError) as e:\n",
        "        print(\"ERROR get the result\")\n",
        "        print(e, end=\"\\n\")\n",
        "    # finish_reason = None\n",
        "    # for response in responses:\n",
        "    #     finish_reason = response.candidates[0].finish_reason\n",
        "\n",
        "    #     if finish_reason == FinishReason.RECITATION \\\n",
        "    #     or finish_reason == FinishReason.PROHIBITED_CONTENT:\n",
        "    #         print(finish_reason, end=\"\\n\")\n",
        "    #         continue\n",
        "    #     try:\n",
        "    #         value = response.candidates[0].text\n",
        "    #         value = response.text\n",
        "    #         if debug: print(value, end=\"\\n\")\n",
        "\n",
        "    #         value = value.replace(\"```tsv\", \"\").replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "\n",
        "    #         result.append(value #+ \" \"\n",
        "    #         )\n",
        "\n",
        "    #     except (ValueError, AttributeError) as e:\n",
        "    #         print(\"ERROR get the result\")\n",
        "    #         print(e, end=\"\\n\")\n",
        "\n",
        "    if debug: print(finish_reason)\n",
        "\n",
        "    if finish_reason != FinishReason.MAX_TOKENS :\n",
        "        isFinished = True\n",
        "        if debug: print(\"isFinished\")\n",
        "        break\n",
        "\n",
        "  if debug: print(\"Done\")\n",
        "  return \"\".join(result)\n",
        "\n",
        "\n",
        "# @retry.Retry(timeout=3000.0)\n",
        "# def transcribe_with_gemini(prompt, mime_type=\"audio/wav\", audio_path=None, data=None, model_name=None, top_p=0.0):\n",
        "\n",
        "#   if model_name is None:\n",
        "#     raise Exception(\"Model name is required\")\n",
        "\n",
        "#   # data or URI\n",
        "#   if audio_path is not None:\n",
        "#     audio1 = Part.from_uri(\n",
        "#       mime_type=mime_type,\n",
        "#       uri=audio_path)\n",
        "#   else:\n",
        "#     audio1 = Part.from_data(data,\n",
        "#         mime_type=mime_type)\n",
        "\n",
        "#   return transcribe_with_gemini_from_part(prompt, audio1, model_name, top_p)\n",
        "\n",
        "@retry.Retry(timeout=3000.0)\n",
        "def transcribe_with_gemini_data(prompt, data=None, mime_type=\"audio/wav\", model_name=None, top_p=0.0):\n",
        "\n",
        "  audio1 = Part.from_data(data,\n",
        "        mime_type=mime_type)\n",
        "\n",
        "  return transcribe_with_gemini_from_part(prompt, audio1, model_name, top_p)\n",
        "\n",
        "@retry.Retry(timeout=3000.0)\n",
        "def transcribe_with_gemini_from_uri(prompt, audio_path, mime_type=\"audio/wav\", model_name=None, top_p=0.0):\n",
        "\n",
        "  audio1 = Part.from_uri(\n",
        "    mime_type=mime_type,\n",
        "    uri=audio_path)\n",
        "\n",
        "  return transcribe_with_gemini_from_part(prompt, audio1, model_name, top_p)\n",
        "\n",
        "if debug:\n",
        "  # uri= 'gs://julien-us/stt_synthetic_tests_data/stt-synthetic-data-rate14-28.wav'\n",
        "  uri=wav_files[0]\n",
        "  result = transcribe_with_gemini_from_uri(prompt, audio_path=uri, model_name=\"gemini-1.5-flash\")\n",
        "  print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 8,
          "status": "ok",
          "timestamp": 1727383490859,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "mWYnm_NjWmvs",
        "outputId": "72ba2b7b-500f-4a2b-d82d-1e5a1051b15c"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "# def generate_gemini_result(wav_text_arr, model_name):\n",
        "#   print(f\"Model: {model_name}\")\n",
        "#   i = 0\n",
        "#   for wav_file, text_file in wav_text_arr:\n",
        "#     print(f\"Processing {i}\")\n",
        "#     bucket, file_wav = split_gcs_uri(wav_file)\n",
        "#     bucket, file_txt = split_gcs_uri(text_file)\n",
        "#     #local_file = f\"{i}-temp.wav\"\n",
        "#     local_file_txt = f\"{i}-ground-truth.txt\"\n",
        "#     #store_temp_file_from_gcs(bucket, file_wav, local_file)\n",
        "#     store_temp_file_from_gcs(bucket, file_txt, local_file_txt)\n",
        "\n",
        "#     result = transcribe_with_gemini(prompt, wav_file, model_name=model_name)\n",
        "#     result= \"\".join(result)\n",
        "\n",
        "#     if not \"gemini\" in model_name :\n",
        "#       model_id = model_name.split(\"/\")[-1]\n",
        "#     else:\n",
        "#       model_id = model_name\n",
        "#     gemini_file = f\"{i}-gemini_{model_id}_result.json\"\n",
        "#     with open(gemini_file, \"w\", encoding=\"UTF8\") as f:\n",
        "#         f.write(result)\n",
        "\n",
        "#     print(80*\"-\")\n",
        "#     print(result)\n",
        "#     print(80*\"-\")\n",
        "\n",
        "#     tags = { \"model_name\": model_name,\n",
        "#             \"file\": file_wav,\n",
        "#             \"ground-truth\": file_txt,\n",
        "#             }\n",
        "#     write_file_to_gcs(bucket,  text_file.replace(\"stt_synthetic_tests_data\", \"stt_synthetic_results\").replace(\".txt\",\"\") + f\"-gemini-{model_id}.txt\",\n",
        "#                       gemini_file, tags )\n",
        "\n",
        "\n",
        "#     with open(local_file_txt, 'r') as f:\n",
        "#       ground_truth = f.read()\n",
        "\n",
        "#     wer, semantic_textual_similarity = evaluate_data([result], [ground_truth])\n",
        "#     print(f\"Results:{wav_file}, WER: {wer}, semantic_textual_similarity: {semantic_textual_similarity}\")\n",
        "\n",
        "#     if system_instruction:\n",
        "#       prompt_log = \"system_instruction:\" + system_instruction + \"\\nprompt:\" +prompt\n",
        "#     else:\n",
        "#       prompt_log = prompt\n",
        "\n",
        "#     data = {\n",
        "#       \"input_file\": wav_file,\n",
        "#       \"ground_truth\": ground_truth,\n",
        "#       \"model_name\": \"gemini_max_token:\"+ model_name,\n",
        "#       \"prompt\": prompt_log,\n",
        "#       #\"system_instruction\": system_instruction,\n",
        "#       \"wer\": wer,\n",
        "#       \"semantic_textual_similarity\": semantic_textual_similarity,\n",
        "#       \"generated_file\": gemini_file,\n",
        "#       \"generated_text\": result\n",
        "#     }\n",
        "#     import pandas as pd\n",
        "#     df = pd.DataFrame( data = [data], columns = [\"input_file\",\"ground_truth\", \"wer\", \"semantic_textual_similarity\",\"generated_file\",\"generated_text\" , \"model_name\", \"prompt\"])\n",
        "#     # return df\n",
        "#     save_results_df_bq(df, table_id, truncate=False)\n",
        "\n",
        "#     i += 1\n",
        "\n",
        "\n",
        "# models_names = [\n",
        "#   # \"gemini-1.5-flash\",\n",
        "#   # \"gemini-1.5-flash-001\",\n",
        "#   # \"gemini-1.5-flash-002\",\n",
        "\n",
        "#   # \"gemini-1.5-pro\",\n",
        "#   # \"gemini-1.5-pro-001\",\n",
        "#   # \"gemini-1.5-pro-002\",\n",
        "#         \"projects/801452371447/locations/us-central1/endpoints/3103157164630343680\",\n",
        "\n",
        "#   ]\n",
        "\n",
        "\n",
        "# for models_name in models_names:\n",
        "#   generate_gemini_result(wav_text_arr, model_name=models_name)\n",
        "# # df = generate_gemini_result(wav_text_arr, model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW4v5lbBVlD1"
      },
      "source": [
        "## Strategy split by silence\n",
        " - Truncate the audio file in segment to avoid the max output token finish raison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1727383490860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "a5e75PnInT06"
      },
      "outputs": [],
      "source": [
        "# utils function to truncate audio file\n",
        "import io\n",
        "import pydub\n",
        "from pydub import AudioSegment\n",
        "\n",
        "root_dir = '.'\n",
        "output_dir = '.'\n",
        "\n",
        "\n",
        "def splitAudio(root_dir, file, start, stop, output_dir):\n",
        "    sound = AudioSegment.from_mp3(root_dir+file)\n",
        "\n",
        "    sound = sound[start:stop]\n",
        "    if debug:\n",
        "      print(f\"file = {file}\")\n",
        "      print(f\"duration_seconds = {sound.duration_seconds}\")\n",
        "      print(f\"sample_width = {sound.sample_width}\")\n",
        "      print(f\"channels = {sound.channels}\")\n",
        "      print(f\"frame_rate = {sound.frame_rate}\")\n",
        "\n",
        "    file_segment = output_dir+file+f\"-{start}-{stop}.wav\"\n",
        "\n",
        "    sound.export(file_segment, format=\"wav\")\n",
        "    return file_segment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1727383490860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "iBZFyZW8p6-I"
      },
      "outputs": [],
      "source": [
        "# generate sequence from audio file split by silences\n",
        "def get_audio_sequence_split_by_silences(file, min_silence_len=500):\n",
        "    from pydub import AudioSegment, silence\n",
        "\n",
        "    myaudio = AudioSegment.from_mp3(file)\n",
        "    dBFS=myaudio.dBFS\n",
        "\n",
        "    # speak = silence.detect_nonsilent(myaudio, min_silence_len=min_silence_len, silence_thresh=dBFS-20, seek_step=10)\n",
        "    # speak_sequences = speak\n",
        "\n",
        "    #speak_sequences = [((start/1000),(stop/1000)) for start,stop in speak] #convert to sec\n",
        "\n",
        "    # print(speak_sequences)\n",
        "\n",
        "    min_silence_len = 600\n",
        "    max_silence_len = 59000\n",
        "    speak_sequences = silence.detect_nonsilent(myaudio, min_silence_len=min_silence_len, silence_thresh=dBFS-20, seek_step=10)\n",
        "\n",
        "    # filter speak_sequences when stop - start are more than 59 secondes\n",
        "    speak_sequences_too_big = [(start, stop) for start, stop in speak_sequences if stop - start > max_silence_len]\n",
        "\n",
        "    while(len(speak_sequences_too_big) > 0 and min_silence_len >=100 ):\n",
        "\n",
        "      min_silence_len =     min (min_silence_len-100, 100)\n",
        "      speak_sequences = silence.detect_nonsilent(myaudio, min_silence_len=min_silence_len, silence_thresh=dBFS-20, seek_step=10)\n",
        "\n",
        "      # filter speak_sequences when stop - start are more than 59 secondes\n",
        "      speak_sequences_too_big = [(start, stop) for start, stop in speak_sequences if stop - start > max_silence_len]\n",
        "      print(\"Sequence more than 59s : \", len(speak_sequences_too_big))\n",
        "      print(f\"min_silence_len = {min_silence_len}\")\n",
        "\n",
        "    # filter speak_sequences when stop - start are less than 1,5 secondes\n",
        "    #speak_sequences_filtered = [(start, stop) for start, stop in speak_sequences if stop - start >= 1500]\n",
        "\n",
        "    return speak_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1727383490860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "CutlB8vDqE2Q",
        "outputId": "53132f61-64d8-4ec2-de07-d6caa073c230"
      },
      "outputs": [],
      "source": [
        "# generate sequence from audio file split by hard split defined by the increment variable\n",
        "def get_audio_sequence_hard_split(file,     INCREMENT = 59*1000):\n",
        "    from pydub import AudioSegment\n",
        "    import math\n",
        "\n",
        "    sound = AudioSegment.from_mp3(file)\n",
        "\n",
        "    if debug: print(f\"duration_seconds = {sound.duration_seconds}\")\n",
        "    duration_ms =  math.ceil(sound.duration_seconds * 1000)\n",
        "    if debug: print(f\"duration_ms = {duration_ms}\")\n",
        "    return [(start, min(start + INCREMENT, duration_ms))\n",
        "            for start in range(0, duration_ms, INCREMENT)]\n",
        "\n",
        "    # speak_sequences = []\n",
        "    # while(finish == False):\n",
        "    #     stop = start+(INCREMENT)\n",
        "    #     if stop > duration_ms:\n",
        "    #         stop = duration_ms\n",
        "    #         finish = True\n",
        "    #     speak_sequences.append((start, stop))\n",
        "    # return speak_sequences\n",
        "    # Instead of a while loop, use a more concise list comprehension\n",
        "\n",
        "\n",
        "# generate one full sequence from audio file\n",
        "def get_one_full_sequence(file):\n",
        "    from pydub import AudioSegment, silence\n",
        "    import math\n",
        "\n",
        "    sound = AudioSegment.from_mp3(file)\n",
        "\n",
        "    if debug: print(f\"duration_seconds = {sound.duration_seconds}\")\n",
        "    #duration_ms = sound.duration_seconds * 1000\n",
        "\n",
        "    duration_ms =  math.ceil(sound.duration_seconds * 1000)\n",
        "    if debug: print(f\"duration_ms = {duration_ms}\")\n",
        "\n",
        "    return [(0, duration_ms)]\n",
        "\n",
        "if debug:\n",
        "  get_audio_sequence_hard_split(\"1-temp.wav\")\n",
        "  get_one_full_sequence(\"1-temp.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1727383490860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "MLm-dM8Cnhlg"
      },
      "outputs": [],
      "source": [
        "# Process a file with a prompt and gemini model apply to the _stt function in parameter\n",
        "def process_local_file_by_chunk(file_name, _stt, _split_sequence_strategy, prompt, model_name):\n",
        "\n",
        "    sound = AudioSegment.from_mp3(file_name )\n",
        "    if debug:\n",
        "      print(f\"duration_seconds = {sound.duration_seconds}\")\n",
        "      print(f\"sample_width = {sound.sample_width}\")\n",
        "      print(f\"channels = {sound.channels}\")\n",
        "      print(f\"frame_rate = {sound.frame_rate}\")\n",
        "\n",
        "    finish = False\n",
        "\n",
        "    results = []\n",
        "\n",
        "    speak_sequences = _split_sequence_strategy(file_name)\n",
        "    for (start, stop) in speak_sequences:\n",
        "\n",
        "        buffer = io.BytesIO()\n",
        "\n",
        "        sound[start:stop].export(buffer, format=\"wav\" )\n",
        "        batch_result = _stt(data = buffer.read(), prompt=prompt, model_name=model_name)\n",
        "        batch_result = \"\".join(batch_result)\n",
        "\n",
        "        print(f\"start = {start} - stop = {stop}\")\n",
        "\n",
        "        results.extend(batch_result+\" \")\n",
        "\n",
        "\n",
        "    return \"\".join(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1727383490860,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "oWr-l-KSVwAl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "\n",
        "def gemini_stt(data, prompt, model_name, uri=None):\n",
        "  return transcribe_with_gemini_data(data=data, prompt=prompt, model_name=model_name)\n",
        "\n",
        "\n",
        "def gemini_stt_gcs(uri, prompt, model_name, data=None):\n",
        "  return transcribe_with_gemini_from_uri(audio_path=uri, prompt=prompt, model_name=model_name)\n",
        "\n",
        "\n",
        "def process_transcriptions(prompt, audio_extention = '.wav'):\n",
        "\n",
        "  for split_strategy in split_strategies_dic:\n",
        "    if debug: print(f\"Split strategy: {split_strategy}\")\n",
        "\n",
        "    for model_name in models_dic:\n",
        "      if debug: print(f\"Model: {model_name}\")\n",
        "      text_files = [string.replace(audio_extention, '.txt') for string in wav_files]\n",
        "      wav_text_arr = zip(wav_files, text_files)\n",
        "\n",
        "      i = 0\n",
        "      for wav_file, text_file in wav_text_arr:\n",
        "        if debug: print(f\"Processing {i}\")\n",
        "        # Store text file locally\n",
        "        bucket, file_txt = split_gcs_uri(text_file)\n",
        "        local_file_txt = f\"{i}-ground-truth.txt\"\n",
        "        store_temp_file_from_gcs(bucket, file_txt, local_file_txt)\n",
        "\n",
        "        _split_strategy = split_strategies_dic[split_strategy]\n",
        "\n",
        "        start_time = time.perf_counter()\n",
        "        if _split_strategy is not None:\n",
        "          # Store local audio file locally\n",
        "          bucket, file_wav = split_gcs_uri(wav_file)\n",
        "          local_file = f\"{i}-temp{audio_extention}\"\n",
        "          store_temp_file_from_gcs(bucket, file_wav, local_file)\n",
        "\n",
        "          result = process_local_file_by_chunk(local_file,\n",
        "                                _stt=models_dic[model_name],\n",
        "                                _split_sequence_strategy=split_strategies_dic[split_strategy],\n",
        "                                prompt=prompt,\n",
        "                                model_name=model_name)\n",
        "        else:\n",
        "          result = transcribe_with_gemini_from_uri(audio_path=wav_file, prompt=prompt, model_name=model_name)\n",
        "\n",
        "        end_time = time.perf_counter()\n",
        "        elapsed_time = end_time - start_time\n",
        "\n",
        "        if debug: print(f\"Elapsed time: {elapsed_time} seconds\")\n",
        "        if not \"gemini\" in model_name :\n",
        "          model_id = model_name.split(\"/\")[-1]\n",
        "        else:\n",
        "          model_id = model_name\n",
        "\n",
        "        gemini_file = f\"{i}-gemini_{split_strategy}_{model_id}_result.txt\"\n",
        "        #gemini_file = f\"{i}-speech_{model_name}_result.json\"\n",
        "        with open(gemini_file, \"w\", encoding=\"UTF8\") as f:\n",
        "            f.write(result)\n",
        "\n",
        "        tags = { \"model_name\": model_name,\n",
        "                \"file\": wav_file,\n",
        "                \"ground-truth\": file_txt,\n",
        "                }\n",
        "\n",
        "        #TODO: #FixMe ugly specific code\n",
        "        write_file_to_gcs(bucket,  text_file.replace(\"stt_synthetic_tests_data\", \"stt_synthetic_results\").replace(\".txt\",\"\") + f\"-gemini_{split_strategy}_{model_id}.txt\",\n",
        "                          gemini_file, tags )\n",
        "\n",
        "        with open(local_file_txt, 'r') as f:\n",
        "          ground_truth = f.read()\n",
        "        ground_truth = ground_truth.replace(\"\\n\", \" \")\n",
        "\n",
        "        wer, semantic_textual_similarity = evaluate_data([result], [ground_truth])\n",
        "        if debug: print(f\"Results:{wav_file}, WER: {wer}, semantic_textual_similarity: {semantic_textual_similarity}\")\n",
        "\n",
        "        if system_instruction:\n",
        "          prompt_log = \"system_instruction:\" + system_instruction + \"\\nprompt:\" +prompt\n",
        "        else:\n",
        "          prompt_log = prompt\n",
        "\n",
        "        data = {\n",
        "          \"input_file\": wav_file,\n",
        "          \"ground_truth\": ground_truth,\n",
        "          \"model_name\": split_strategy+model_name,\n",
        "          \"prompt\": prompt_log,\n",
        "          \"wer\": wer,\n",
        "          \"processing_time\": elapsed_time,\n",
        "          \"semantic_textual_similarity\": semantic_textual_similarity,\n",
        "          \"generated_file\": gemini_file,\n",
        "          \"generated_text\": result\n",
        "        }\n",
        "        import pandas as pd\n",
        "        df = pd.DataFrame( data = [data], columns = [\"input_file\",\"ground_truth\", \"wer\", \"semantic_textual_similarity\",\"generated_file\",\"generated_text\" , \"model_name\", \"prompt\", \"processing_time\"])\n",
        "\n",
        "      #   break\n",
        "      # break\n",
        "        save_results_df_bq(df, table_id, truncate=False)\n",
        "\n",
        "        i += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "elapsed": 121907,
          "status": "ok",
          "timestamp": 1727397974483,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "46m6unH9CWC2",
        "outputId": "5466bbde-ecc1-4f5a-b1a9-f3e1b608e2e9"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "models_dic = {\n",
        "  \"gemini-1.5-pro\": gemini_stt,\n",
        "  \"gemini-1.5-pro-001\": gemini_stt,\n",
        "  \"gemini-1.5-pro-002\": gemini_stt,\n",
        "  \"gemini-1.5-flash-002\": gemini_stt,\n",
        "  \"gemini-1.5-flash\": gemini_stt,\n",
        "  \"projects/801452371447/locations/us-central1/endpoints/3103157164630343680\": gemini_stt,\n",
        "}\n",
        "\n",
        "split_strategies_dic = {\n",
        "\n",
        "  \"no_split:\"         : get_one_full_sequence,\n",
        "  \"gcs_max_token:\"    : None,\n",
        "  \"split_by_silences:\": get_audio_sequence_split_by_silences,\n",
        "  \"hard_split:\"       : get_audio_sequence_hard_split,\n",
        "}\n",
        "\n",
        "process_transcriptions(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1727397974484,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "ig-Lnrnp7RXU",
        "outputId": "8a391579-fd7b-4b1d-b6f2-b96f1b5accd7"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "system_instruction = \"\"\"<ai_role>\n",
        "  You are an AI transcriptionist specializing in interviews.\n",
        "  Your primary function is to convert spoken language from audio files into accurate, well-formatted text. Audio files are in french, transcriptions are in french.\n",
        "  Ensure the transcribed text is clear and readable.\n",
        "  Add ponctuation like comma, question mark, exclamation mark, etc.\n",
        "  Ignore background audio.\n",
        "</ai_role>\n",
        "<answer_format>\n",
        "Output full word only.\n",
        "Do not generate any other text.\n",
        "Do not truncate words.\n",
        "</answer_format>\n",
        "\"\"\"\n",
        "\n",
        "prompt = \"\"\"Generate a transcription in French of the audio, only extract speech and ignore background audio.\n",
        "Transcribe spoken words.\n",
        "\"\"\"\n",
        "\n",
        "process_transcriptions(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1727397974484,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "JuEVJXmd7Ras"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1727397974484,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "j2tHDlBCFete"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# %%time\n",
        "\n",
        "# import os\n",
        "# import json\n",
        "\n",
        "# text_files = [string.replace('.wav', '.txt') for string in wav_files]\n",
        "\n",
        "# wav_text_arr = zip(wav_files, text_files)\n",
        "# # prompt = \"transcribe spoken words\"\n",
        "# # prompt = \"\"\"Generate a transcription in French of the audio, only extract speech and ignore background audio.\n",
        "# # \"\"\"\n",
        "\n",
        "# def generate_gemini_result(wav_text_arr, model_name):\n",
        "#   print(f\"Model: {model_name}\")\n",
        "#   i = 0\n",
        "#   for wav_file, text_file in wav_text_arr:\n",
        "#     print(f\"Processing {i}\")\n",
        "#     bucket, file_wav = split_gcs_uri(wav_file)\n",
        "#     bucket, file_txt = split_gcs_uri(text_file)\n",
        "#     local_file = f\"{i}-temp.wav\"\n",
        "#     local_file_txt = f\"{i}-ground-truth.txt\"\n",
        "#     store_temp_file_from_gcs(bucket, file_wav, local_file)\n",
        "#     store_temp_file_from_gcs(bucket, file_txt, local_file_txt)\n",
        "\n",
        "#     result = transcribe_with_gemini(prompt, wav_file)\n",
        "#     result= \"\".join(result)\n",
        "\n",
        "#     gemini_file = f\"{i}-gemini_{model_name}_result.json\"\n",
        "#     with open(gemini_file, \"w\", encoding=\"UTF8\") as f:\n",
        "#         f.write(result)\n",
        "\n",
        "#     print(80*\"-\")\n",
        "#     print(result)\n",
        "#     print(80*\"-\")\n",
        "\n",
        "#     tags = { \"model_name\": model_name,\n",
        "#             \"file\": file_wav,\n",
        "#             \"ground-truth\": file_txt,\n",
        "#             }\n",
        "#     write_file_to_gcs(bucket,  text_file.replace(\"stt_synthetic_tests_data\", \"stt_synthetic_results\").replace(\".txt\",\"\") + f\"-gemini-{model_name}.txt\",\n",
        "#                       gemini_file, tags )\n",
        "\n",
        "\n",
        "#     with open(local_file_txt, 'r') as f:\n",
        "#       ground_truth = f.read()\n",
        "\n",
        "#     wer, semantic_textual_similarity = evaluate_data([result], [ground_truth])\n",
        "#     print(f\"Results:{wav_file}, WER: {wer}, semantic_textual_similarity: {semantic_textual_similarity}\")\n",
        "\n",
        "#     data = {\n",
        "#       \"input_file\": wav_file,\n",
        "#       \"ground_truth\": ground_truth,\n",
        "#       \"model_name\": #\"gemini:\"+\n",
        "#                     model_name,\n",
        "#       \"prompt\": \"system_instruction:\" + system_instruction + \"\\nprompt:\" +prompt,\n",
        "#       #\"system_instruction\": system_instruction,\n",
        "#       \"wer\": wer,\n",
        "#       \"semantic_textual_similarity\": semantic_textual_similarity,\n",
        "#       \"generated_file\": gemini_file,\n",
        "#       \"generated_text\": result\n",
        "#     }\n",
        "#     import pandas as pd\n",
        "#     df = pd.DataFrame( data = [data], columns = [\"input_file\",\"ground_truth\", \"wer\", \"semantic_textual_similarity\",\"generated_file\",\"generated_text\" , \"model_name\", \"prompt\"])\n",
        "#     # return df\n",
        "#     save_results_df_bq(df, table_id, truncate=False)\n",
        "\n",
        "#     i += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # df = generate_gemini_result(wav_text_arr, model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1727397974484,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "9ZH4FBxxQm-e"
      },
      "outputs": [],
      "source": [
        "# import jiwer\n",
        "\n",
        "# def process_words(df, idx):\n",
        "#   out = jiwer.process_words(\n",
        "#       [df['ground_truth'][idx]],\n",
        "#       [df['generated_text'][idx]],\n",
        "#   )\n",
        "\n",
        "#   print(jiwer.visualize_alignment(out))\n",
        "\n",
        "# def process_words_str(ground_truth, generated_text):\n",
        "#   out = jiwer.process_words(\n",
        "#       [ground_truth],\n",
        "#       [generated_text],\n",
        "#   )\n",
        "\n",
        "#   print(jiwer.visualize_alignment(out))\n",
        "\n",
        "# def process_words_list(ground_truth, generated_text):\n",
        "#   out = jiwer.process_words(\n",
        "#       ground_truth,\n",
        "#       generated_text,\n",
        "#   )\n",
        "\n",
        "#   print(jiwer.visualize_alignment(out))\n",
        "\n",
        "# process_words(df, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1727397974484,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "T4o_K1Q5DGpb"
      },
      "outputs": [],
      "source": [
        "# idx = 0\n",
        "# ground_truths = df['ground_truth'][idx].split(\"\\n\")\n",
        "# generated_texts = df['generated_text'][idx].split(\"\\n\")\n",
        "# for ground_truth, generated_text in zip(ground_truths, generated_texts):\n",
        "#   if len(generated_text) > 0:\n",
        "#     process_words_str(ground_truth.replace(\"  \",\" \"), generated_text.replace(\"  \",\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1727397974484,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "mgO4ALnyukTo"
      },
      "outputs": [],
      "source": [
        "# idx = 0\n",
        "# ground_truths = df['ground_truth'][idx].replace(\"\\n\",\" \")\n",
        "# generated_texts = df['generated_text'][idx].replace(\"\\n\",\" \")\n",
        "# process_words_str(ground_truths.replace(\"  \",\" \"), generated_texts.replace(\"  \",\" \"))\n",
        "\n",
        "# # for ground_truth, generated_text in zip(ground_truths, generated_texts):\n",
        "# #   if len(generated_text) > 0:\n",
        "# #     process_words_str(ground_truth, generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1727397974484,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "BtRY7VnUH47m"
      },
      "outputs": [],
      "source": [
        "# df['generated_text'][idx].split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1727397974484,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "mGjMqrxZHlQb"
      },
      "outputs": [],
      "source": [
        "# df['ground_truth'][idx].split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1727397974484,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "Usw06GOstW_k"
      },
      "outputs": [],
      "source": [
        "# df['generated_text'][idx].split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1727397974485,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "MX2B5eOeoGut"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# And generate chapter based on this transcript. \n",
        "## TODO: Implement prompt based on result of previous STT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#TODO"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "STT gemini benchmark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
